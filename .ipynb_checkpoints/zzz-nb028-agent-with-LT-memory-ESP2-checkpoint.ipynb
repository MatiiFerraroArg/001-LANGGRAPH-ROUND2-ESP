{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d3704f-6553-49ee-9b4e-453a8e92de1b",
   "metadata": {},
   "source": [
    "# Agente con Memoria a Largo Plazo\n",
    "* Construiremos un Agente que nos ayudará a **gestionar una lista de tareas pendientes (ToDo list)**.  \n",
    "* Decidirá:  \n",
    "    * **cuándo guardar elementos** en nuestra lista de tareas.  \n",
    "    * **si guardar un perfil de usuario o una colección de tareas pendientes**.  \n",
    "* Además de la memoria semántica (semantic memory, hechos sobre el usuario), también tendrá **memoria procedural (procedural memory)**.  \n",
    "    * Recuerda que la memoria procedural es el system prompt. Esto permitirá al usuario establecer preferencias para la creación de tareas pendientes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248bc93c-b860-48f2-a4d9-e973983ef472",
   "metadata": {},
   "source": [
    "## Ruta de aprendizaje recomendada  \n",
    "Este es un proyecto excelente para aprender y practicar todo lo que has aprendido hasta ahora.  \n",
    "\n",
    "1. Mira el video completo. Concéntrate en comprender los conceptos principales.  \n",
    "2. Repite todos los pasos desde cero por tu cuenta. Enfócate en entender los detalles. Tómate tu tiempo.  \n",
    "3. Reflexiona. Planifica una lista de experimentos interesantes para modificar y mejorar el proyecto.  \n",
    "4. Experimenta con una pequeña funcionalidad a la vez: clona el proyecto y prueba solo con esa funcionalidad.  \n",
    "5. Y otra vez, y otra vez, y otra vez. Hasta dominarlo. Con la mentalidad y la motivación de un atleta olímpico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f76a83-a98a-4186-83dc-d3aa1f429bb7",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065e336-d054-412c-8a3f-1fbec63e1bcd",
   "metadata": {},
   "source": [
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dda8d4-80cf-4b8f-9981-94edda5e9911",
   "metadata": {},
   "source": [
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 028-agent-with-LT-memory.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e766aa-f3e2-491f-be99-d0c6b700d47a",
   "metadata": {},
   "source": [
    "## Track operations\n",
    "From now on, we can track the operations **and the cost** of this project from LangSmith:\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f99504a-1b8f-4360-b342-0b81ffa06aff",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e5789-5bde-42e1-88dd-92dc8e363c24",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5514113-ddca-4ae9-9de6-0b9225b18f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef1e5c-b7e2-4a04-96c5-8f64377b8eba",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d23f4-61f5-4227-8a75-7eefde6680ee",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df978ec5-bfd2-4167-bd33-86bc2687d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel35 = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chatModel4o = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2de7a30-7b1c-427e-b546-1a8219aeecfd",
   "metadata": {},
   "source": [
    "## ¿Qué está haciendo TrustCall en el background?  \n",
    "* TrustCall nos permite comprender mejor sus operaciones. Aquí te mostraremos cómo **descubrir qué llamadas (calls) a herramientas (tools) ha realizado TrustCall**.  \n",
    "* **Agregaremos un listener al extractor de TrustCall**. Esto permitirá que las ejecuciones del extractor pasen a una clase (class) llamada `Spy`, que definiremos. La clase `Spy` extraerá **información sobre qué llamadas a herramientas ha realizado TrustCall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a86d69a-5ad7-4fe2-a0b5-e99ac201b8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "\n",
    "class MemoryCollection(BaseModel):\n",
    "    memories: list[Memory] = Field(description=\"A list of memories about the user.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "414a242c-603b-4d9a-9b1f-ea61364bba3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Inspect the tool calls made by Trustcall\n",
    "class Spy:\n",
    "    def __init__(self):\n",
    "        self.called_tools = []\n",
    "\n",
    "    def __call__(self, run):\n",
    "        # Collect information about the tool calls made by the extractor.\n",
    "        q = [run]\n",
    "        while q:\n",
    "            r = q.pop()\n",
    "            if r.child_runs:\n",
    "                q.extend(r.child_runs)\n",
    "            if r.run_type == \"chat_model\":\n",
    "                self.called_tools.append(\n",
    "                    r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
    "                )\n",
    "\n",
    "# Initialize the spy\n",
    "spy = Spy()\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    tool_choice=\"Memory\",\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "# PAY ATTENTION HERE: see how we add the spy listener.\n",
    "# Add the spy as a listener\n",
    "trustcall_extractor_see_all_tool_calls = trustcall_extractor.with_listeners(on_end=spy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15743b8e-9205-4c1e-834b-c9dd7e0ac04a",
   "metadata": {},
   "source": [
    "## Por si tienes curiosidad sobre cómo se desarrolló el Spy...  \n",
    "La clase **Spy** rastrea las llamadas a herramientas realizadas durante la ejecución de un proceso relacionado con modelos de chat de IA o un marco de extracción como LangChain.  \n",
    "\n",
    "Veámoslo paso a paso:\n",
    "\n",
    "#### 1. La clase `Spy`  \n",
    "- La clase está diseñada para **registrar llamadas a herramientas** dentro de una ejecución.  \n",
    "- Tiene un atributo `self.called_tools`, que es una lista donde almacena las llamadas detectadas.  \n",
    "\n",
    "#### 2. El método `__call__`  \n",
    "- Esto hace que la clase pueda llamarse como una función.  \n",
    "- Recibe un objeto `run` (representando una tarea en ejecución).  \n",
    "- Utiliza una cola (`q`) para **recorrer todas las ejecuciones hijas** (ejecuciones anidadas).  \n",
    "\n",
    "#### 3. Procesamiento de ejecuciones (runs)  \n",
    "- El bucle extrae **child runs** de forma recursiva, lo que significa que revisa todos los niveles de ejecución.  \n",
    "- Si la ejecución (`r`) es de tipo `\"chat_model\"`, extrae información sobre las llamadas a herramientas desde `r.outputs`.  \n",
    "\n",
    "#### 4. Extracción de llamadas a herramientas  \n",
    "- Las llamadas a herramientas se acceden mediante:  \n",
    "  ```python\n",
    "  r.outputs[\"generations\"][0][0][\"message\"][\"kwargs\"][\"tool_calls\"]\n",
    "  ```\n",
    "  - `generations[0][0]`: Se refiere a la primera respuesta generada.  \n",
    "  - `\"message\"` → `\"kwargs\"` → `\"tool_calls\"`: Navega a través de un formato estructurado de datos (probablemente JSON) para recuperar la información sobre la llamada a herramientas.  \n",
    "- La información extraída se almacena en `self.called_tools`.  \n",
    "\n",
    "#### 5. Inicialización del Spy  \n",
    "```python\n",
    "spy = Spy()\n",
    "```\n",
    "- Esto crea una instancia de la clase `Spy`, lista para inspeccionar las llamadas a herramientas.  \n",
    "\n",
    "#### Resumen (Explicación sencilla)  \n",
    "- La clase **Spy** rastrea las herramientas utilizadas durante un proceso.  \n",
    "- Recorre el historial de ejecución, incluyendo llamadas anidadas.  \n",
    "- Si el proceso involucra un **modelo de chat**, extrae los detalles de las herramientas utilizadas.  \n",
    "- La información extraída se guarda en `self.called_tools` para su posterior análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d88d289-a48d-41a6-8036-e24045d3516f",
   "metadata": {},
   "source": [
    "## OK. Primero vamos a utilizar TrustCall sin el listener."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc0919ff-c87a-4f61-85f6-7cd439f220e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Instruction\n",
    "instruction = \"\"\"Extract memories from the following conversation:\"\"\"\n",
    "\n",
    "# Conversation\n",
    "conversation = [HumanMessage(content=\"Hi, I'm Julio.\"), \n",
    "                AIMessage(content=\"Nice to meet you, Julio.\"), \n",
    "                HumanMessage(content=\"Yesterday I visited Sausalito.\")]\n",
    "\n",
    "# PAY ATTENTION HERE: we use the regular extractor.\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction)] + conversation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0af2a4f-e71e-4f2b-9a08-a04de8790a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_FrmbmeMKdSV8uQqdCQncKQW3)\n",
      " Call ID: call_FrmbmeMKdSV8uQqdCQncKQW3\n",
      "  Args:\n",
      "    content: Julio visited Sausalito yesterday.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "71f5e37e-0856-4a58-9fde-250d27f17759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Julio visited Sausalito yesterday.'\n"
     ]
    }
   ],
   "source": [
    "# Responses contain the memories that adhere to the schema\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2cd2c32-5c7b-470b-b581-d89501607e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_FrmbmeMKdSV8uQqdCQncKQW3'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3038467b-a5d2-4438-a5df-0ea84ad0ffaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0', 'Memory', {'content': 'Julio visited Sausalito yesterday.'})]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Update the conversation\n",
    "updated_conversation = [AIMessage(content=\"That's great, what did you do after?\"), \n",
    "                        HumanMessage(content=\"I went to Tiburon and prepared a paella in the park.\"),                        \n",
    "                        AIMessage(content=\"What else is on your mind?\"),\n",
    "                        HumanMessage(content=\"I was thinking about finally learn to cook paella for the sake of my girlfriend.\"),]\n",
    "\n",
    "# Update the instruction\n",
    "system_msg = \"\"\"Update existing memories and create new ones based on the following conversation:\"\"\"\n",
    "\n",
    "# We'll save existing memories, giving them an ID, key (tool name), and value\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8693d425-aaaa-4a77-80ce-c06e362f72a4",
   "metadata": {},
   "source": [
    "## Y ahora utilicemos TrustCall con el listener"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7891c5e-17cb-4ae7-9886-43f1d52a081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAY ATTENTION HERE: See how we use the extractor with the listener.\n",
    "# Invoke the extractor with our updated conversation and existing memories\n",
    "result = trustcall_extractor_see_all_tool_calls.invoke({\"messages\": updated_conversation, \n",
    "                                                        \"existing\": existing_memories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7a59be0-7b94-4391-ab92-7647d7cb246b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_5pJ8BF9bsiFnFRUpXtbbqA2D', 'json_doc_id': '0'}\n",
      "{'id': 'call_Q3BjEuPA8PDzjLo70w0lL8rC'}\n"
     ]
    }
   ],
   "source": [
    "# Metadata contains the tool call  \n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "691b5555-b69a-4409-96db-41deef2b2b35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_5pJ8BF9bsiFnFRUpXtbbqA2D)\n",
      " Call ID: call_5pJ8BF9bsiFnFRUpXtbbqA2D\n",
      "  Args:\n",
      "    content:  I went to Tiburon and prepared a paella in the park.\n",
      "  Memory (call_Q3BjEuPA8PDzjLo70w0lL8rC)\n",
      " Call ID: call_Q3BjEuPA8PDzjLo70w0lL8rC\n",
      "  Args:\n",
      "    content: I was thinking about finally learning to cook paella for the sake of my girlfriend.\n"
     ]
    }
   ],
   "source": [
    "# Messages contain the tool calls\n",
    "for m in result[\"messages\"]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c2a1d6f-8d0f-4720-a41c-1627ffa68fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=' I went to Tiburon and prepared a paella in the park.'\n",
      "content='I was thinking about finally learning to cook paella for the sake of my girlfriend.'\n"
     ]
    }
   ],
   "source": [
    "# Parsed responses\n",
    "for m in result[\"responses\"]:\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd008686-c03f-407d-9173-12fdf53ac44a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'name': 'PatchDoc',\n",
       "   'args': {'json_doc_id': '0',\n",
       "    'planned_edits': 'Add the new memory content about visiting Tiburon and preparing paella in the park to the existing Memory instance.',\n",
       "    'patches': [{'op': 'add',\n",
       "      'path': '/content',\n",
       "      'value': ' I went to Tiburon and prepared a paella in the park.'}]},\n",
       "   'id': 'call_5pJ8BF9bsiFnFRUpXtbbqA2D',\n",
       "   'type': 'tool_call'},\n",
       "  {'name': 'Memory',\n",
       "   'args': {'content': 'I was thinking about finally learning to cook paella for the sake of my girlfriend.'},\n",
       "   'id': 'call_Q3BjEuPA8PDzjLo70w0lL8rC',\n",
       "   'type': 'tool_call'}]]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the tool calls made by Trustcall\n",
    "spy.called_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685fd900-0941-4457-81dc-fb6c56dde03e",
   "metadata": {},
   "source": [
    "## Revisemos lo que acabamos de hacer\n",
    "\n",
    "El código anterior demuestra cómo **rastrear llamadas a herramientas** realizadas por el **extractor TrustCall** en un flujo de procesamiento de conversaciones utilizando LangGraph. Aquí tienes una explicación simplificada de cada parte:\n",
    "\n",
    "\n",
    "#### Definir Schemas de Memoria  \n",
    "- **`Memory`** y **`MemoryCollection`** definen la estructura para almacenar la información extraída.  \n",
    "- Ejemplo: Los recuerdos pueden incluir datos sobre el usuario, como *\"El usuario visitó Sausalito ayer.\"*  \n",
    "\n",
    "\n",
    "#### Crear una Clase Spy  \n",
    "- **`Spy`** realiza un seguimiento de qué herramientas usa TrustCall durante el procesamiento.  \n",
    "- Inspecciona y registra las llamadas a herramientas incrustadas en la estructura **`run`**, capturando detalles sobre las interacciones.  \n",
    "\n",
    "\n",
    "#### Configurar el LLM y el Extractor  \n",
    "- **El modelo (`ChatOpenAI`)** simula el procesamiento de conversaciones.  \n",
    "- **El extractor TrustCall** se configura para:  \n",
    "  - Usar la herramienta **`Memory`**.  \n",
    "  - Insertar automáticamente recuerdos extraídos de las conversaciones.  \n",
    "\n",
    "El extractor procesa los mensajes del usuario e identifica información relevante para almacenarla como recuerdos.  \n",
    "\n",
    "\n",
    "#### Adjuntar Spy al Extractor  \n",
    "- Se modifica el extractor (`with_listeners`) para usar el objeto **Spy**.  \n",
    "- **Spy** escucha las llamadas a herramientas al final del proceso de extracción.  \n",
    "\n",
    "\n",
    "#### Procesar Conversaciones  \n",
    "- Las conversaciones se envían al extractor con una **instrucción** para extraer recuerdos.  \n",
    "- El extractor genera:\n",
    "  1. **Mensajes** – La conversación procesada.  \n",
    "  2. **Respuestas** – Los recuerdos extraídos.  \n",
    "  3. **Metadatos** – Información sobre las herramientas utilizadas.  \n",
    "\n",
    "\n",
    "#### Actualizar Conversaciones y Recuerdos  \n",
    "- Se agrega una nueva conversación con instrucciones actualizadas.  \n",
    "- Se proporcionan **recuerdos existentes** para permitir actualizaciones y nuevas adiciones.  \n",
    "- El extractor procesa las actualizaciones y genera nuevos datos.  \n",
    "\n",
    "\n",
    "#### Inspeccionar Llamadas a Herramientas  \n",
    "- **Spy** recopila y registra todas las llamadas a herramientas utilizadas durante el proceso.  \n",
    "- Permite a los desarrolladores ver qué herramientas se invocaron y analizar cómo interactuó el extractor con ellas.  \n",
    "\n",
    "\n",
    "#### Propósito del Código  \n",
    "Este código se utiliza principalmente para **depurar y monitorear** el comportamiento del extractor TrustCall. Ayuda a los desarrolladores a comprender cómo TrustCall usa herramientas para procesar y extraer información durante las conversaciones, asegurando transparencia y permitiendo mejoras en el flujo de procesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b58d29b-6dfc-4a0f-b63e-d73a24d0400e",
   "metadata": {},
   "source": [
    "## Bien. Es útil saber todo eso. Ahora comencemos a construir nuestro Agente de Tareas.  \n",
    "\n",
    "Nuestro Agente podrá decidir cuándo actualizar 3 elementos en la memoria a largo plazo:  \n",
    "* Datos del perfil del usuario.  \n",
    "* Elementos de la lista de tareas pendientes (ToDo List).  \n",
    "* Prompt del sistema (System prompt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6713bb79-f9e9-4e5e-baab-34fcfb7bccf4",
   "metadata": {},
   "source": [
    "## Crearemos la clase UpdateMemory para seleccionar el elemento de la memoria a largo plazo que actualizaremos en un momento determinado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0527515-7a7a-4b25-abfa-4416aa0f0e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "\n",
    "# Update memory tool\n",
    "class UpdateMemory(TypedDict):\n",
    "    \"\"\" Decision on what memory type to update \"\"\"\n",
    "    update_type: Literal['user', 'todo', 'instructions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f09f49-bdc8-4643-9b88-5139aa6fd848",
   "metadata": {},
   "source": [
    "## Revisemos el código anterior  \n",
    "\n",
    "#### `TypedDict`  \n",
    "- Se usa para crear una estructura similar a un diccionario donde cada clave tiene un nombre y un tipo específico.  \n",
    "\n",
    "#### `UpdateMemory`  \n",
    "- Una **clase** que actúa como un diccionario para representar una **decisión sobre qué tipo de memoria actualizar**.  \n",
    "- Tiene una clave: **`update_type`**, que especifica el tipo de memoria que debe actualizarse.  \n",
    "\n",
    "#### `Literal`  \n",
    "- Limita el valor de **`update_type`** a **tres opciones predefinidas**:  \n",
    "     - `'user'` – Actualiza recuerdos relacionados con el usuario.  \n",
    "     - `'todo'` – Actualiza recuerdos relacionados con la lista de tareas pendientes.  \n",
    "     - `'instructions'` – Actualiza instrucciones o directrices almacenadas en memoria.  \n",
    "\n",
    "#### Ejemplo de uso  \n",
    "```python\n",
    "update = UpdateMemory(update_type='user')  # Válido\n",
    "update = UpdateMemory(update_type='todo')  # Válido\n",
    "update = UpdateMemory(update_type='notes') # Error! 'notes' no está permitido.\n",
    "```\n",
    "\n",
    "#### Propósito  \n",
    "Este código ayuda a **categorizar las actualizaciones de memoria** en tipos específicos, organizando mejor el sistema y reduciendo errores durante las actualizaciones. Garantiza que solo se pasen tipos de memoria válidos, mejorando la fiabilidad del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e999197-5781-4e16-ba92-4428fcc05791",
   "metadata": {},
   "source": [
    "## Con eso listo, ahora concentrémonos en construir el agente  \n",
    "* Utilizaremos el **router `route_message`** para tomar una decisión binaria sobre si guardar recuerdos o no.  \n",
    "* La **actualización de la colección de memoria (collection memory)** será gestionada por **TrustCall** en el nodo `write_memory`, tal y como lo hicimos antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2275312c-bda8-4047-baa2-1a2041f711b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from datetime import datetime\n",
    "from trustcall import create_extractor\n",
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import merge_message_runs, HumanMessage, SystemMessage\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, END, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# User profile schema\n",
    "class Profile(BaseModel):\n",
    "    \"\"\"This is the profile of the user you are chatting with\"\"\"\n",
    "    name: Optional[str] = Field(description=\"The user's name\", default=None)\n",
    "    location: Optional[str] = Field(description=\"The user's location\", default=None)\n",
    "    job: Optional[str] = Field(description=\"The user's job\", default=None)\n",
    "    connections: list[str] = Field(\n",
    "        description=\"Personal connection of the user, such as family members, friends, or coworkers\",\n",
    "        default_factory=list\n",
    "    )\n",
    "    interests: list[str] = Field(\n",
    "        description=\"Interests that the user has\", \n",
    "        default_factory=list\n",
    "    )\n",
    "\n",
    "# ToDo schema\n",
    "class ToDo(BaseModel):\n",
    "    task: str = Field(description=\"The task to be completed.\")\n",
    "    time_to_complete: Optional[int] = Field(description=\"Estimated time to complete the task (minutes).\")\n",
    "    deadline: Optional[datetime] = Field(\n",
    "        description=\"When the task needs to be completed by (if applicable)\",\n",
    "        default=None\n",
    "    )\n",
    "    solutions: list[str] = Field(\n",
    "        description=\"List of specific, actionable solutions (e.g., specific ideas, service providers, or concrete options relevant to completing the task)\",\n",
    "        min_items=1,\n",
    "        default_factory=list\n",
    "    )\n",
    "    status: Literal[\"not started\", \"in progress\", \"done\", \"archived\"] = Field(\n",
    "        description=\"Current status of the task\",\n",
    "        default=\"not started\"\n",
    "    )\n",
    "\n",
    "# Create the Trustcall extractor for updating the user profile \n",
    "profile_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Profile],\n",
    "    tool_choice=\"Profile\",\n",
    ")\n",
    "\n",
    "# Chatbot instruction for choosing what to update and what tools to call \n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. \n",
    "\n",
    "You are designed to be a companion to a user, helping them keep track of their ToDo list.\n",
    "\n",
    "You have a long term memory which keeps track of three things:\n",
    "1. The user's profile (general information about them) \n",
    "2. The user's ToDo list\n",
    "3. General instructions for updating the ToDo list\n",
    "\n",
    "Here is the current User Profile (may be empty if no information has been collected yet):\n",
    "<user_profile>\n",
    "{user_profile}\n",
    "</user_profile>\n",
    "\n",
    "Here is the current ToDo List (may be empty if no tasks have been added yet):\n",
    "<todo>\n",
    "{todo}\n",
    "</todo>\n",
    "\n",
    "Here are the current user-specified preferences for updating the ToDo list (may be empty if no preferences have been specified yet):\n",
    "<instructions>\n",
    "{instructions}\n",
    "</instructions>\n",
    "\n",
    "Here are your instructions for reasoning about the user's messages:\n",
    "\n",
    "1. Reason carefully about the user's messages as presented below. \n",
    "\n",
    "2. Decide whether any of the your long-term memory should be updated:\n",
    "- If personal information was provided about the user, update the user's profile by calling UpdateMemory tool with type `user`\n",
    "- If tasks are mentioned, update the ToDo list by calling UpdateMemory tool with type `todo`\n",
    "- If the user has specified preferences for how to update the ToDo list, update the instructions by calling UpdateMemory tool with type `instructions`\n",
    "\n",
    "3. Tell the user that you have updated your memory, if appropriate:\n",
    "- Do not tell the user you have updated the user's profile\n",
    "- Tell the user them when you update the todo list\n",
    "- Do not tell the user that you have updated instructions\n",
    "\n",
    "4. Err on the side of updating the todo list. No need to ask for explicit permission.\n",
    "\n",
    "5. Respond naturally to user user after a tool call was made to save memories, or if no tool call was made.\"\"\"\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction. \n",
    "\n",
    "Use the provided tools to retain any necessary memories about the user. \n",
    "\n",
    "Use parallel tool calling to handle updates and insertions simultaneously.\n",
    "\n",
    "System Time: {time}\"\"\"\n",
    "\n",
    "# Instructions for updating the ToDo list\n",
    "CREATE_INSTRUCTIONS = \"\"\"Reflect on the following interaction.\n",
    "\n",
    "Based on this interaction, update your instructions for how to update ToDo list items. \n",
    "\n",
    "Use any feedback from the user to update how they like to have items added, etc.\n",
    "\n",
    "Your current instructions are:\n",
    "\n",
    "<current_instructions>\n",
    "{current_instructions}\n",
    "</current_instructions>\"\"\"\n",
    "\n",
    "# Node definitions\n",
    "def task_mAIstro(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve profile memory from the store\n",
    "    namespace = (\"profile\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        user_profile = memories[0].value\n",
    "    else:\n",
    "        user_profile = None\n",
    "\n",
    "    # Retrieve task memory from the store\n",
    "    namespace = (\"todo\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    todo = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
    "\n",
    "    # Retrieve custom instructions\n",
    "    namespace = (\"instructions\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        instructions = memories[0].value\n",
    "    else:\n",
    "        instructions = \"\"\n",
    "    \n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.bind_tools([UpdateMemory], parallel_tool_calls=False).invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "def update_profile(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"profile\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"Profile\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = profile_extractor.invoke({\"messages\": updated_messages, \n",
    "                                         \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated profile\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "\n",
    "# PAY ATTENTION HERE: We needed to define this function, that is used in the next one.\n",
    "# Did the LangGraph team miss this or are we missing something???\n",
    "def extract_tool_info(tool_calls, tool_name):\n",
    "    \"\"\"Extracts and summarizes information about tool calls.\"\"\"\n",
    "    updates = []\n",
    "    for tool_call in tool_calls:\n",
    "        if tool_call:\n",
    "            for call in tool_call:\n",
    "                if call['name'] == tool_name:\n",
    "                    # Collect the arguments or details about the tool call\n",
    "                    updates.append(f\"Updated {tool_name}: {call['args']}\")\n",
    "    return \"\\n\".join(updates) if updates else f\"No updates for {tool_name}.\"\n",
    "\n",
    "\n",
    "def update_todos(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"todo\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"ToDo\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    TRUSTCALL_INSTRUCTION_FORMATTED=TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Initialize the spy for visibility into the tool calls made by Trustcall\n",
    "    spy = Spy()\n",
    "    \n",
    "    # Create the Trustcall extractor for updating the ToDo list \n",
    "    todo_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[ToDo],\n",
    "    tool_choice=tool_name,\n",
    "    enable_inserts=True\n",
    "    ).with_listeners(on_end=spy)\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = todo_extractor.invoke({\"messages\": updated_messages, \n",
    "                                    \"existing\": existing_memories})\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "        \n",
    "    # Respond to the tool call made in task_mAIstro, confirming the update\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "\n",
    "    # PAY ATTENTION: here is where the function extract_tool_info is being used.\n",
    "    # We needed to define it in order to prevent an error. See the previous function definition.\n",
    "    # Extract the changes made by Trustcall and add the the ToolMessage returned to task_mAIstro\n",
    "    todo_update_msg = extract_tool_info(spy.called_tools, tool_name)\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": todo_update_msg, \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "def update_instructions(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    \n",
    "    namespace = (\"instructions\", user_id)\n",
    "\n",
    "    existing_memory = store.get(namespace, \"user_instructions\")\n",
    "        \n",
    "    # Format the memory in the system prompt\n",
    "    system_msg = CREATE_INSTRUCTIONS.format(current_instructions=existing_memory.value if existing_memory else None)\n",
    "    new_memory = model.invoke([SystemMessage(content=system_msg)]+state['messages'][:-1] + [HumanMessage(content=\"Please update the instructions based on the conversation\")])\n",
    "\n",
    "    # Overwrite the existing memory in the store \n",
    "    key = \"user_instructions\"\n",
    "    store.put(namespace, key, {\"memory\": new_memory.content})\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated instructions\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "# Conditional edge\n",
    "def route_message(state: MessagesState, config: RunnableConfig, store: BaseStore) -> Literal[END, \"update_todos\", \"update_instructions\", \"update_profile\"]:\n",
    "\n",
    "    \"\"\"Reflect on the memories and chat history to decide whether to update the memory collection.\"\"\"\n",
    "    message = state['messages'][-1]\n",
    "    if len(message.tool_calls) ==0:\n",
    "        return END\n",
    "    else:\n",
    "        tool_call = message.tool_calls[0]\n",
    "        if tool_call['args']['update_type'] == \"user\":\n",
    "            return \"update_profile\"\n",
    "        elif tool_call['args']['update_type'] == \"todo\":\n",
    "            return \"update_todos\"\n",
    "        elif tool_call['args']['update_type'] == \"instructions\":\n",
    "            return \"update_instructions\"\n",
    "        else:\n",
    "            raise ValueError\n",
    "\n",
    "# Create the graph + all nodes\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define the flow of the memory extraction process\n",
    "builder.add_node(task_mAIstro)\n",
    "builder.add_node(update_todos)\n",
    "builder.add_node(update_profile)\n",
    "builder.add_node(update_instructions)\n",
    "builder.add_edge(START, \"task_mAIstro\")\n",
    "builder.add_conditional_edges(\"task_mAIstro\", route_message)\n",
    "builder.add_edge(\"update_todos\", \"task_mAIstro\")\n",
    "builder.add_edge(\"update_profile\", \"task_mAIstro\")\n",
    "builder.add_edge(\"update_instructions\", \"task_mAIstro\")\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# We compile the graph with the checkpointer and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1585760a-956a-48d6-b921-6221dd9f962f",
   "metadata": {},
   "source": [
    "## Desglosemos el código paso a paso  \n",
    "\n",
    "El código anterior configura un **sistema de chatbot basado en conversaciones** utilizando LangGraph y TrustCall para gestionar y actualizar la **memoria a largo plazo** (perfil del usuario, lista de tareas y preferencias de instrucciones) según las entradas del usuario. Aquí tienes una **explicación simplificada** de cada parte:\n",
    "\n",
    "#### Definir schemas para la memoria  \n",
    "- **Schema de Perfil:**  \n",
    "  Almacena información personal del usuario, como nombre, ubicación, trabajo, conexiones e intereses.  \n",
    "- **Schema de Tareas (ToDo):**  \n",
    "  Gestiona tareas con detalles como fechas límite, estado y soluciones.  \n",
    "\n",
    "#### Extractores de TrustCall  \n",
    "- **Extractor de Perfil:**  \n",
    "  Actualiza el perfil del usuario en función de las conversaciones.  \n",
    "- **Extractor de Tareas:**  \n",
    "  Actualiza la lista de tareas según la entrada del chat.  \n",
    "- **Actualizador de Instrucciones:**  \n",
    "  Modifica las instrucciones del chatbot para gestionar tareas según las preferencias del usuario.  \n",
    "\n",
    "Cada extractor trabaja con herramientas diseñadas específicamente para procesar estos schemas y almacenar la información relevante.\n",
    "\n",
    "#### Instrucciones para el Chatbot  \n",
    "- **`MODEL_SYSTEM_MESSAGE`**  \n",
    "  Dirige al chatbot para:  \n",
    "  1. Actualizar el perfil si el usuario comparte información personal.  \n",
    "  2. Actualizar la lista de tareas si se mencionan nuevas tareas.  \n",
    "  3. Modificar instrucciones en función de las preferencias del usuario.  \n",
    "- **`TRUSTCALL_INSTRUCTION`**  \n",
    "  Asegura que los datos extraídos se reflejen como memoria utilizando herramientas de TrustCall.  \n",
    "\n",
    "#### Definir nodos (funciones) para actualizaciones de memoria  \n",
    "- **`task_mAIstro`**  \n",
    "  Carga la memoria existente (perfil, tareas e instrucciones) y responde según la entrada (input) del usuario, decidiendo qué actualizar.  \n",
    "- **`update_profile`**  \n",
    "  Modifica el perfil del usuario si se detecta información personal en los mensajes.  \n",
    "- **`update_todos`**  \n",
    "  Actualiza la lista de tareas con nuevas tareas o cambios según la entrada (input) del usuario.  \n",
    "- **`update_instructions`**  \n",
    "  Modifica las preferencias del chatbot según cómo el usuario quiera gestionar la lista de tareas.  \n",
    "\n",
    "Cada función:  \n",
    "1. Carga la memoria existente desde el almacenamiento.  \n",
    "2. Procesa los mensajes del chat.  \n",
    "3. Guarda la memoria actualizada en la base de datos.  \n",
    "4. Confirma los cambios al usuario si es necesario.  \n",
    "\n",
    "#### Enrutamiento de decisiones  \n",
    "- **`route_message`**  \n",
    "  Decide qué nodo ejecutar según la última herramienta utilizada:  \n",
    "  - Si se detecta una actualización del perfil → **`update_profile`**  \n",
    "  - Si se detecta una actualización de tareas → **`update_todos`**  \n",
    "  - Si se detecta una actualización de instrucciones → **`update_instructions`**  \n",
    "  - Si no se necesita actualización → **finaliza el procesamiento**  \n",
    "\n",
    "#### Construcción del flujo de conversación  \n",
    "- **StateGraph:**  \n",
    "  Define el flujo de conversación:  \n",
    "  1. Comienza en **`task_mAIstro`** para procesar las entradas.  \n",
    "  2. Redirige las actualizaciones al perfil, tareas o instrucciones según sea necesario.  \n",
    "  3. Vuelve al inicio para seguir procesando nuevas entradas.  \n",
    "\n",
    "- **Gestión de Memoria:**  \n",
    "  - **`InMemoryStore`**: Almacena la memoria a largo plazo a través de múltiples interacciones.  \n",
    "  - **`MemorySaver`**: Rastrea la memoria a corto plazo de la conversación actual.  \n",
    "\n",
    "#### Visualización del Gráfico  \n",
    "- Genera un **diagrama de flujo** usando Mermaid.js para visualizar las conexiones entre los nodos del chatbot.  \n",
    "\n",
    "#### Ejemplo de Flujo de Trabajo  \n",
    "**Entrada:**  \n",
    "*Usuario: \"Necesito terminar un informe para el viernes.\"*  \n",
    "\n",
    "**Proceso:**  \n",
    "1. Detecta una tarea y la agrega a la lista de pendientes.  \n",
    "2. Guarda `\"Terminar informe\"` con la fecha límite del viernes.  \n",
    "3. Confirma la adición de la tarea al usuario.  \n",
    "\n",
    "**Salida (Output):**  \n",
    "*Bot: \"He agregado 'Terminar informe' a tu lista de tareas con fecha límite el viernes.\"*  \n",
    "\n",
    "#### Resumen  \n",
    "Este sistema permite interacciones dinámicas impulsadas por **memoria**, haciendo que el chatbot sea más **inteligente** y **consciente del contexto** con el tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd5eae3-026b-4ff6-9bb0-0297aaf4de18",
   "metadata": {},
   "source": [
    "## Ese ha sido un buen resumen. Ahora profundicemos en las partes más relevantes de este código."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d143d42-9263-4c88-aa70-8bbe0de3de68",
   "metadata": {},
   "source": [
    "## Revisemos el segmento que define los schemas para las memorias de **Perfil** y **Tareas (ToDo)**  \n",
    "\n",
    "Este segmento de código define **estructuras de datos** para almacenar información sobre el usuario y sus tareas, utilizando la biblioteca **Pydantic** de Python. Su objetivo es garantizar que los datos se almacenen de manera organizada y validada según formatos predefinidos.  \n",
    "\n",
    "#### Schema de Perfil del Usuario (`Profile`)  \n",
    "\n",
    "Esta clase representa **información personal** del usuario.  \n",
    "\n",
    "- **`name`**: Almacena el nombre del usuario (opcional).  \n",
    "- **`location`**: Almacena la ubicación del usuario (opcional).  \n",
    "- **`job`**: Almacena la profesión o trabajo del usuario (opcional).  \n",
    "- **`connections`**: Una lista de personas conectadas con el usuario (por ejemplo, familia, amigos o compañeros de trabajo).  \n",
    "  - El valor por defecto es una **lista vacía**.  \n",
    "- **`interests`**: Una lista de intereses o pasatiempos del usuario.  \n",
    "  - El valor por defecto es una **lista vacía**.  \n",
    "\n",
    "**Propósito:**  \n",
    "Permite hacer un seguimiento de los detalles personales del usuario para **personalizar respuestas** y adaptar las interacciones en función de su perfil.  \n",
    "\n",
    "#### Schema de Tareas (`ToDo`)  \n",
    "\n",
    "Esta clase define la estructura para almacenar y gestionar **tareas pendientes**.  \n",
    "\n",
    "- **`task`**: Descripción de la tarea a completar (**obligatorio**).  \n",
    "- **`time_to_complete`**: Tiempo estimado para completar la tarea, en minutos (opcional).  \n",
    "- **`deadline`**: Fecha y hora específica en la que la tarea debe completarse (opcional).  \n",
    "- **`solutions`**: Lista de **pasos accionables o ideas** para completar la tarea.  \n",
    "  - Debe contener al menos **una solución** y el valor por defecto es una **lista vacía**.  \n",
    "- **`status`**: Estado actual de la tarea.  \n",
    "  - Puede tomar uno de los siguientes valores:  \n",
    "    - `\"not started\"` (**predeterminado**)  \n",
    "    - `\"in progress\"`  \n",
    "    - `\"done\"`  \n",
    "    - `\"archived\"`  \n",
    "\n",
    "**Propósito:**  \n",
    "Gestiona la **lista de tareas pendientes**, almacenando tareas, fechas límite y estados para que el chatbot pueda **hacer seguimiento y actualizar actividades** de manera eficiente.  \n",
    "\n",
    "#### Ejemplo de Datos  \n",
    "\n",
    "**Perfil del Usuario:**  \n",
    "```python\n",
    "profile = Profile(\n",
    "    name=\"Alice\",\n",
    "    location=\"San Francisco\",\n",
    "    job=\"Engineer\",\n",
    "    connections=[\"Bob\", \"Carol\"],\n",
    "    interests=[\"hiking\", \"photography\"]\n",
    ")\n",
    "```\n",
    "\n",
    "**Tarea ToDo:**  \n",
    "```python\n",
    "task = ToDo(\n",
    "    task=\"Finish project report\",\n",
    "    time_to_complete=120,\n",
    "    deadline=datetime(2024, 12, 31, 17, 0),\n",
    "    solutions=[\"Draft outline\", \"Add visuals\", \"Proofread\"],\n",
    "    status=\"in progress\"\n",
    ")\n",
    "```\n",
    "\n",
    "#### Cómo encaja en el código  \n",
    "- El schema **Profile** permite la **personalización** al almacenar información sobre el usuario.  \n",
    "- El schema **ToDo** gestiona **tareas y actualizaciones**, lo que permite que el chatbot **haga seguimiento del progreso** y sugiera soluciones.  \n",
    "- Ambos esquemas se integran con **TrustCall** para **extraer, actualizar y almacenar información automáticamente** durante las conversaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6d6638-bee7-4be8-8160-39b2f319ed5f",
   "metadata": {},
   "source": [
    "## El extractor de TrustCall es tan fácil que no requiere explicación\n",
    "* Como puedes ver en el código, no hay nada nuevo en la definición del extractor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdec447-a2e9-4c84-9f7b-cd1f4ec4aeb8",
   "metadata": {},
   "source": [
    "## Eso ha sido muy interesante. Ahora revisemos el segmento donde damos instrucciones al chatbot.  \n",
    "\n",
    "Este segmento del código define **instrucciones para el chatbot** que guían su comportamiento al interactuar con el usuario. Su objetivo es asegurarse de que el chatbot sepa cómo **analizar los mensajes**, **decidir qué actualizar** y **responder adecuadamente**. Aquí tienes una explicación sencilla de cada parte:  \n",
    "\n",
    "#### Instrucciones del Chatbot (`MODEL_SYSTEM_MESSAGE`)  \n",
    "Esta sección define el **rol y las reglas** que debe seguir el chatbot al procesar conversaciones.  \n",
    "\n",
    "- **Rol:**  \n",
    "  El chatbot es un **asistente útil** diseñado para:  \n",
    "  1. Mantener un **perfil del usuario** (información personal).  \n",
    "  2. Gestionar la **lista de tareas (ToDo List)**.  \n",
    "  3. Seguir **preferencias** del usuario para la gestión de tareas (instrucciones).  \n",
    "\n",
    "- **Contexto de Datos:**  \n",
    "  Se proporciona al chatbot el **state actual** de:  \n",
    "  - **Perfil del usuario:** Detalles personales.  \n",
    "  - **Lista de tareas:** Tareas pendientes.  \n",
    "  - **Instrucciones:** Preferencias para gestionar las tareas.  \n",
    "\n",
    "- **Reglas de Decisión:**  \n",
    "  El chatbot analiza los mensajes del usuario y decide:  \n",
    "  1. **Actualizar el perfil:** Si el usuario comparte información personal (nombre, ubicación, etc.).  \n",
    "  2. **Actualizar la lista de tareas:** Si se mencionan tareas o fechas límite.  \n",
    "  3. **Actualizar las instrucciones:** Si el usuario expresa preferencias sobre la gestión de tareas.  \n",
    "\n",
    "- **Respuestas:**  \n",
    "  - **Notificar** al usuario cuando se **actualiza la lista de tareas**.  \n",
    "  - **No notificar** cuando se actualiza el **perfil** o las **instrucciones** para evitar interrupciones innecesarias.  \n",
    "  - **Priorizar siempre la actualización de la lista de tareas** sin pedir confirmación.  \n",
    "\n",
    "- **Regla Final:**  \n",
    "  Después de analizar la entrada (input) del usuario, el chatbot **debe responder de forma natural** para continuar la conversación, ya sea que haya actualizaciones o no.  \n",
    "\n",
    "#### Instrucción para TrustCall (`TRUSTCALL_INSTRUCTION`)  \n",
    "Esta es una **plantilla de instrucciones** para que TrustCall maneje la actualización de la memoria de manera eficiente.  \n",
    "\n",
    "- **Propósito:**  \n",
    "  Indica a TrustCall que:  \n",
    "  1. **Analice la interacción** y decida qué datos almacenar.  \n",
    "  2. Use **llamadas de herramientas en paralelo** para **actualizar múltiples memorias** al mismo tiempo (por ejemplo, el perfil y las tareas).  \n",
    "\n",
    "- **Marcador de Tiempo del Sistema (System Time Placeholder):**  \n",
    "  Incluye la **hora actual** para proporcionar contexto a las actualizaciones (especialmente útil para rastrear fechas límite).  \n",
    "\n",
    "#### Instrucciones para Actualizar la Lista de Tareas (`CREATE_INSTRUCTIONS`)  \n",
    "Esta plantilla se usa para **ajustar las instrucciones** sobre cómo el chatbot debe gestionar las actualizaciones de la lista de tareas.  \n",
    "\n",
    "- **Propósito:**  \n",
    "  Basado en **comentarios del usuario**, el chatbot puede:  \n",
    "  1. **Modificar reglas** para agregar o actualizar tareas.  \n",
    "  2. **Reflejar preferencias** como qué nivel de detalle se necesita en las tareas o si se deben enviar recordatorios.  \n",
    "\n",
    "- **Marcador de Instrucciones Actuales:**  \n",
    "  Incluye las **instrucciones existentes** como contexto y permite que el chatbot las **refine** según interacciones recientes.  \n",
    "\n",
    "#### Ejemplo Simplificado del Flujo de Trabajo  \n",
    "\n",
    "#### Escenario 1: Creación de tareas  \n",
    "**Usuario:**  \n",
    "*\"Necesito reservar un vuelo para la próxima semana y hacer seguimiento de mi solicitud de visa.\"*  \n",
    "\n",
    "**Acciones del Chatbot:**  \n",
    "1. Detecta **tareas** → Actualiza la lista de tareas.  \n",
    "2. Prioriza la actualización sin pedir confirmación.  \n",
    "3. Responde: *\"He agregado 'Reservar un vuelo para la próxima semana' y 'Hacer seguimiento de la solicitud de visa' a tu lista de tareas.\"*  \n",
    "\n",
    "#### Escenario 2: Modificación de instrucciones  \n",
    "**Usuario (después):**  \n",
    "*\"Recuérdame estas tareas un día antes de las fechas límite.\"*  \n",
    "\n",
    "**Acciones del Chatbot:**  \n",
    "1. **Actualiza las instrucciones** según la solicitud del usuario.  \n",
    "2. **No notifica** al usuario sobre esta actualización, pero la usa para enviar recordatorios en el futuro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a63d9f-af6f-40bf-91e0-744c9983bdd4",
   "metadata": {},
   "source": [
    "## Excelente. Ahora revisemos el segmento donde definimos los nodos.  \n",
    "\n",
    "Este segmento define **cuatro funciones** (llamadas **nodos**) que manejan diferentes tareas en el **sistema de gestión de memoria del chatbot**. Cada función es responsable de **actualizar un tipo específico de memoria** (perfil, lista de tareas o instrucciones) o de **procesar la entrada (input) del usuario** para decidir qué debe actualizarse.  \n",
    "\n",
    "#### NODO `task_mAIstro`: Cargar memorias y generar una respuesta  \n",
    "\n",
    "**¿Qué hace?**  \n",
    "- **Propósito:**  \n",
    "  Carga las memorias existentes (**perfil, tareas, instrucciones**) y **personaliza las respuestas** según los datos del usuario.  \n",
    "\n",
    "**Pasos:**  \n",
    "1. **Identificar al usuario:**  \n",
    "   Obtiene el **ID del usuario** desde la configuración para recuperar sus datos.  \n",
    "\n",
    "2. **Recuperar memorias:**  \n",
    "   - **Perfil:** Carga información personal guardada (nombre, ubicación, etc.).  \n",
    "   - **Lista de tareas:** Carga tareas y fechas límite.  \n",
    "   - **Instrucciones:** Carga preferencias sobre la gestión de tareas.  \n",
    "\n",
    "3. **Preparar el mensaje del sistema:**  \n",
    "   Formatea el **mensaje del sistema** del chatbot con los datos actuales del usuario.  \n",
    "4. **Responder al usuario:**  \n",
    "   Utiliza el **modelo de chat** para generar una respuesta teniendo en cuenta los mensajes del usuario y las memorias guardadas.  \n",
    "\n",
    "**Salida (Output):**  \n",
    "Devuelve el **mensaje de respuesta del chatbot** para continuar la conversación.  \n",
    "\n",
    "#### NODO `update_profile`: Actualizar el perfil del usuario  \n",
    "\n",
    "**¿Qué hace?**  \n",
    "- **Propósito:**  \n",
    "  Comprueba si el usuario ha mencionado **información personal** (por ejemplo, nombre, trabajo) y **actualiza su perfil**.  \n",
    "\n",
    "**Pasos:**  \n",
    "1. **Recuperar el perfil existente:**  \n",
    "   Carga los datos de perfil guardados para proporcionar contexto.  \n",
    "\n",
    "2. **Preparar mensajes:**  \n",
    "   Combina el historial del chat y las instrucciones para que TrustCall analice los mensajes.  \n",
    "\n",
    "3. **Extraer nueva información:**  \n",
    "   Usa el **extractor de TrustCall** para detectar y extraer **detalles nuevos del perfil**.  \n",
    "\n",
    "4. **Guardar actualizaciones del perfil:**  \n",
    "   Almacena el **perfil actualizado** en la base de datos de memoria.  \n",
    "\n",
    "5. **Notificar al chatbot:**  \n",
    "   Confirma que el perfil ha sido actualizado (**pero no informa directamente al usuario**).  \n",
    "\n",
    "**Salida (Output):**  \n",
    "Devuelve un **mensaje de herramienta** confirmando la actualización para que el chatbot lo use internamente.  \n",
    "\n",
    "#### NODO `update_todos`: Actualizar la lista de tareas  \n",
    "\n",
    "> **Nota:** El nodo `update_todos` usa la función `extract_tool_info`.  \n",
    "> Explicamos esta función en términos simples en la siguiente sección.  \n",
    "\n",
    "**¿Qué hace?**  \n",
    "- **Propósito:**  \n",
    "  Detecta y **actualiza tareas** en la lista de tareas del usuario según la conversación.  \n",
    "\n",
    "**Pasos:**  \n",
    "1. **Recuperar tareas existentes:**  \n",
    "   Carga las tareas guardadas para comprobar si hay actualizaciones o nuevas tareas.  \n",
    "\n",
    "2. **Preparar mensajes:**  \n",
    "   Formatea el historial del chat y las instrucciones para que TrustCall analice los datos.  \n",
    "\n",
    "3. **Espiar llamadas a herramientas:**  \n",
    "   Agrega un **\"espía\"** para rastrear las llamadas a herramientas realizadas por TrustCall para fines de depuración (debugging).  \n",
    "\n",
    "4. **Extraer actualizaciones de tareas:**  \n",
    "   Usa el **extractor de TrustCall** para identificar **nuevas tareas o actualizaciones** y las almacena.  \n",
    "\n",
    "5. **Notificar al chatbot y al usuario:**  \n",
    "   Confirma las actualizaciones en la lista de tareas y **notifica al usuario** sobre los cambios.  \n",
    "\n",
    "**Salida (Output):**  \n",
    "Devuelve un **mensaje de herramienta** resumiendo las actualizaciones para que el chatbot las transmita al usuario.  \n",
    "\n",
    "#### NODO `update_instructions`: Actualizar las preferencias de gestión de tareas  \n",
    "\n",
    "**¿Qué hace?**  \n",
    "- **Propósito:**  \n",
    "  Actualiza las **instrucciones** del chatbot sobre cómo gestionar tareas según las preferencias del usuario.  \n",
    "\n",
    "**Pasos:**  \n",
    "1. **Recuperar instrucciones actuales:**  \n",
    "   Carga las preferencias existentes, si las hay.  \n",
    "\n",
    "2. **Preparar mensaje:**  \n",
    "   Formatea un mensaje para **reflejar y actualizar preferencias** según la última interacción.  \n",
    "\n",
    "3. **Generar nuevas instrucciones:**  \n",
    "   Usa el **modelo de chat** para crear **instrucciones revisadas** sobre la gestión de tareas.  \n",
    "\n",
    "4. **Guardar las actualizaciones:**  \n",
    "   Sobrescribe las **instrucciones existentes** en la memoria con la nueva versión.  \n",
    "\n",
    "5. **Notificar al chatbot:**  \n",
    "   Confirma que las instrucciones han sido actualizadas (**pero no notifica al usuario**).  \n",
    "\n",
    "**Salida (Output):**  \n",
    "Devuelve un **mensaje de herramienta** confirmando la actualización para que el chatbot lo use internamente.  \n",
    "\n",
    "#### Propósito general de los nodos  \n",
    "\n",
    "Estas funciones:  \n",
    "1. **Cargan y analizan los datos** almacenados en memoria.  \n",
    "2. **Deciden qué actualizar** según la entrada del usuario (perfil, tareas o instrucciones).  \n",
    "3. **Actualizan y guardan la memoria** utilizando los extractores de TrustCall.  \n",
    "4. **Informan al chatbot** (y a veces al usuario) sobre las actualizaciones para mantener la conversación contextualizada.  \n",
    "\n",
    "#### Ejemplo Simplificado del Flujo de Trabajo  \n",
    "\n",
    "**Usuario:**  \n",
    "*\"Me mudé a Nueva York y necesito reservar un vuelo para el viernes.\"*  \n",
    "\n",
    "**Paso a paso del proceso:**  \n",
    "\n",
    "1. **`task_mAIstro`:**  \n",
    "   Detecta que el usuario mencionó un **nuevo lugar de residencia** y una **nueva tarea**.  \n",
    "\n",
    "2. **`update_profile`:**  \n",
    "   Actualiza el **perfil** con \"Nueva York\" como ubicación.  \n",
    "\n",
    "3. **`update_todos`:**  \n",
    "   Agrega \"Reservar un vuelo para el viernes\" a la **lista de tareas** y **notifica al usuario**.  \n",
    "\n",
    "4. **`update_instructions`:**  \n",
    "   Verifica si el usuario mencionó alguna preferencia (por ejemplo, recordatorios) y **actualiza las instrucciones** si es necesario.  \n",
    "\n",
    "**Respuesta del Chatbot:**  \n",
    "*\"He agregado 'Reservar un vuelo para el viernes' a tu lista de tareas.\"*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5ffa2c-dc9a-433b-8863-a2e7877bab12",
   "metadata": {},
   "source": [
    "## Explicación línea por línea de la función `task_mAIstro`  \n",
    "\n",
    "La función `task_mAIstro` es el nodo principal en el flujo de trabajo de LangGraph. Su propósito es recuperar la información almacenada sobre el usuario y sus tareas, y luego generar una respuesta basada en esos datos.\n",
    "\n",
    "#### Definición de la Función\n",
    "```python\n",
    "def task_mAIstro(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "```\n",
    "- **`state`**: Contiene el historial de chat (mensajes entre el usuario y el chatbot).  \n",
    "- **`config`**: Contiene configuraciones adicionales (como el ID del usuario).  \n",
    "- **`store`**: Almacena la memoria a largo plazo, como el perfil del usuario y sus tareas.  \n",
    "\n",
    "#### Paso 1: Obtener el ID del Usuario\n",
    "```python\n",
    "user_id = config[\"configurable\"][\"user_id\"]\n",
    "```\n",
    "- Extrae el **identificador único del usuario** de la configuración.  \n",
    "- Este ID se usa para **buscar los datos correctos** en el almacenamiento.  \n",
    "\n",
    "#### Paso 2: Recuperar el Perfil del Usuario\n",
    "```python\n",
    "namespace = (\"profile\", user_id)\n",
    "memories = store.search(namespace)\n",
    "if memories:\n",
    "    user_profile = memories[0].value\n",
    "else:\n",
    "    user_profile = None\n",
    "```\n",
    "- **Busca en el almacenamiento** si hay información de **perfil guardada** (nombre, ubicación, trabajo, intereses).  \n",
    "- Si el perfil **existe**, se almacena en `user_profile`.  \n",
    "- Si **no se encuentra ningún perfil**, se asigna `None`.  \n",
    "\n",
    "#### Paso 3: Recuperar la Lista de Tareas (To-Do List)\n",
    "```python\n",
    "namespace = (\"todo\", user_id)\n",
    "memories = store.search(namespace)\n",
    "todo = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
    "```\n",
    "- **Busca en el almacenamiento** si hay una **lista de tareas guardada**.  \n",
    "- Si hay tareas, las **convierte en un solo string formateado**.  \n",
    "\n",
    "#### Paso 4: Recuperar Preferencias del Usuario\n",
    "```python\n",
    "namespace = (\"instructions\", user_id)\n",
    "memories = store.search(namespace)\n",
    "if memories:\n",
    "    instructions = memories[0].value\n",
    "else:\n",
    "    instructions = \"\"\n",
    "```\n",
    "- **Busca en el almacenamiento** si hay **preferencias guardadas** del usuario sobre la gestión de tareas.  \n",
    "- Si existen preferencias, se asignan a `instructions`; si no, se deja vacío `\"\"`.  \n",
    "\n",
    "#### Paso 5: Formatear el Mensaje del Sistema**\n",
    "```python\n",
    "system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, todo=todo, instructions=instructions)\n",
    "```\n",
    "- **Rellena la plantilla de mensaje del sistema** (`MODEL_SYSTEM_MESSAGE`) con:\n",
    "  - **Perfil del usuario**.  \n",
    "  - **Lista de tareas**.  \n",
    "  - **Preferencias de actualización de tareas**.  \n",
    "- Esto asegura que el chatbot **tenga contexto** antes de generar una respuesta.  \n",
    "\n",
    "#### Paso 6: Generar una Respuesta\n",
    "```python\n",
    "response = model.bind_tools([UpdateMemory], parallel_tool_calls=False).invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "```\n",
    "- Llama al **modelo de IA (`gpt-4o`)** para procesar el mensaje del usuario junto con la **memoria recuperada**.  \n",
    "- Usa la **herramienta `UpdateMemory`** para manejar cualquier actualización de memoria necesaria.  \n",
    "- La función **`invoke`** envía el **mensaje del sistema + historial de conversación** al modelo.  \n",
    "- La IA **genera una respuesta** basada en la información almacenada.  \n",
    "\n",
    "#### Paso 7: Devolver la Respuesta\n",
    "```python\n",
    "return {\"messages\": [response]}\n",
    "```\n",
    "- **Devuelve la respuesta generada por el chatbot**.  \n",
    "- Esta respuesta será enviada **al usuario** en la conversación.  \n",
    "\n",
    "#### Resumen de lo que hace `task_mAIstro`\n",
    "1. **Recupera los datos del usuario** (perfil, tareas, preferencias) desde la memoria. \n",
    "2. **Formatea un mensaje del sistema** con esta información.  \n",
    "3. **Envía el mensaje formateado + historial de chat** al modelo de IA (al modelo LLM).  \n",
    "5. **Genera y devuelve una respuesta personalizada** del chatbot.  \n",
    "\n",
    "Esta función garantiza que el chatbot **recuerde conversaciones pasadas** y **responda de manera personalizada**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72bd1b8-f71b-4332-8be6-50b3f2f64627",
   "metadata": {},
   "source": [
    "## Explicación línea por línea de la función `update_profile`  \n",
    "\n",
    "La función `update_profile` **analiza el historial del chat** y **actualiza la información del perfil del usuario** en la memoria a largo plazo.  \n",
    "\n",
    "#### Definición de la función\n",
    "```python\n",
    "def update_profile(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "```\n",
    "- **`state`**: Contiene el historial de conversación (mensajes intercambiados entre el usuario y el chatbot).  \n",
    "- **`config`**: Configuración de la aplicación (incluye el ID del usuario).  \n",
    "- **`store`**: **Sistema de almacenamiento de memoria** donde se guardan los perfiles de los usuarios.  \n",
    "\n",
    "#### Paso 1: Obtener el ID del usuario\n",
    "```python\n",
    "user_id = config[\"configurable\"][\"user_id\"]\n",
    "```\n",
    "- Extrae el **identificador único del usuario**.  \n",
    "- Este ID se usa para recuperar y actualizar el **perfil correcto** del usuario.  \n",
    "\n",
    "#### Paso 2: Definir la ubicación de almacenamiento del perfil\n",
    "```python\n",
    "namespace = (\"profile\", user_id)\n",
    "```\n",
    "- Crea un **namespace** para almacenar los **datos del perfil**.  \n",
    "- Esto garantiza que las actualizaciones se guarden en la categoría correcta.  \n",
    "\n",
    "#### Paso 3: Recuperar información del perfil existente\n",
    "```python\n",
    "existing_items = store.search(namespace)\n",
    "```\n",
    "- **Verifica si ya existe información del perfil** en la memoria.  \n",
    "- Si el usuario **ha compartido detalles de su perfil antes**, estos se almacenan en `existing_items`.  \n",
    "\n",
    "#### Paso 4: Formatear los datos del perfil para su procesamiento\n",
    "```python\n",
    "tool_name = \"Profile\"\n",
    "existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                      for existing_item in existing_items]\n",
    "                      if existing_items\n",
    "                      else None\n",
    "                    )\n",
    "```\n",
    "- Si hay **detalles de perfil existentes**, se **formatean** en una lista estructurada.  \n",
    "- Si **no hay datos previos del perfil**, se establece en `None`.  \n",
    "\n",
    "#### Paso 5: Preparar la instrucción del sistema\n",
    "```python\n",
    "TRUSTCALL_INSTRUCTION_FORMATTED = TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
    "```\n",
    "- Formatea la **plantilla de instrucción del sistema** (`TRUSTCALL_INSTRUCTION`) insertando la **marca de tiempo actual**.  \n",
    "- Esta instrucción ayuda a la IA (el modelo LLM) a comprender qué hacer con la nueva información del usuario.  \n",
    "\n",
    "#### Paso 6: Fusionar (merge) el historial de chat para su procesamiento\n",
    "```python\n",
    "updated_messages = list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "```\n",
    "- **Fusiona** la **instrucción** con los últimos mensajes del usuario.  \n",
    "- La función **excluye el último mensaje** en `state[\"messages\"]` porque ese es el llamado a la herramienta en sí.  \n",
    "\n",
    "#### Paso 7: Extraer la información actualizada del perfil\n",
    "```python\n",
    "result = profile_extractor.invoke({\"messages\": updated_messages, \n",
    "                                   \"existing\": existing_memories})\n",
    "```\n",
    "- Llama al **extractor de perfil** (`profile_extractor`) para analizar los mensajes.  \n",
    "- **Identifica nuevos detalles del perfil** en la conversación del usuario.  \n",
    "- Usa **datos de perfil existentes (si los hay)** como contexto.  \n",
    "\n",
    "#### Paso 8: Almacenar la información del perfil actualizado\n",
    "```python\n",
    "for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "    store.put(namespace,\n",
    "              rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "              r.model_dump(mode=\"json\"),\n",
    "    )\n",
    "```\n",
    "- **Recorre las actualizaciones del perfil extraídas**.  \n",
    "- **Guarda la información actualizada** en la memoria (`store.put()`).  \n",
    "- Si la actualización **no tiene un ID**, se genera un nuevo **UUID** (identificador único).  \n",
    "\n",
    "#### Paso 9: Enviar un mensaje de confirmación\n",
    "```python\n",
    "tool_calls = state['messages'][-1].tool_calls\n",
    "return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated profile\", \"tool_call_id\": tool_calls[0]['id']}]}\n",
    "```\n",
    "- Recupera el **ID de la llamada original a la herramienta** para vincular la actualización con la solicitud correcta.  \n",
    "- **Devuelve una respuesta** para confirmar que el perfil ha sido actualizado.  \n",
    "\n",
    "#### Resumen de lo que hace `update_profile`\n",
    "1. **Recupera los datos del perfil del usuario** (si están disponibles).  \n",
    "2. **Formatea los datos del perfil** para su procesamiento.  \n",
    "3. **Prepara un mensaje de instrucción** para guiar la extracción de la IA.  \n",
    "4. **Analiza el historial del chat** para detectar actualizaciones en el perfil.  \n",
    "5. **Almacena cualquier actualización del perfil** en la memoria.  \n",
    "6. **Devuelve un mensaje de confirmación** para indicar que la actualización fue exitosa.  \n",
    "\n",
    "Esta función permite que el chatbot **recuerde detalles del usuario** (nombre, ubicación, intereses, etc.) y **los mantenga actualizados**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012b3011-7976-4252-be88-674be5abb7ce",
   "metadata": {},
   "source": [
    "## Acerca de la función extract_tool_info utilizada por el nodo update_todos\n",
    "\n",
    "Tuvimos que agregar la función auxiliar **`extract_tool_info`** para que este código funcionara. **No estaba originalmente en el proyecto preparado por el equipo de LangGraph**. Esta función se utiliza para analizar y resumir información sobre llamadas a herramientas (acciones realizadas por el sistema para actualizar o gestionar datos). A continuación, se presenta una explicación sencilla sobre la codificación de esta función (puedes ver el código antes del nodo update_todos):\n",
    "\n",
    "#### ¿Qué hace?\n",
    "La función:\n",
    "1. **Recibe entrada**:  \n",
    "   - Una lista de llamadas a herramientas (`tool_calls`) realizadas durante el proceso del chatbot.  \n",
    "   - El nombre de una herramienta específica (`tool_name`) que nos interesa analizar.  \n",
    "\n",
    "2. **Encuentra las llamadas a herramientas relevantes**:  \n",
    "   - Recorre todas las llamadas a herramientas para verificar si el nombre de la herramienta coincide con el especificado.  \n",
    "\n",
    "3. **Extrae información**:  \n",
    "   - Para las llamadas a herramientas coincidentes, recopila detalles sobre qué argumentos o actualizaciones se realizaron con esa herramienta.  \n",
    "\n",
    "4. **Formatea un resumen**:  \n",
    "   - Crea un resumen legible de las actualizaciones realizadas por la herramienta.  \n",
    "   - Si no se encontraron actualizaciones, devuelve un mensaje indicándolo.  \n",
    "\n",
    "#### Explicación paso a paso\n",
    "1. **Inicializa una lista vacía**:  \n",
    "   - `updates = []`: Esta lista almacenará el resumen de las actualizaciones para la herramienta especificada.  \n",
    "\n",
    "2. **Recorre las llamadas a herramientas**:  \n",
    "   ```python\n",
    "   for tool_call in tool_calls:\n",
    "   ```\n",
    "   - Cada `tool_call` se revisa para ver si contiene actualizaciones.  \n",
    "\n",
    "3. **Bucle anidado para llamadas individuales**:  \n",
    "   ```python\n",
    "   for call in tool_call:\n",
    "   ```\n",
    "   - Se examina cada `call` dentro de un `tool_call`.  \n",
    "\n",
    "4. **Coincidencia con el nombre de la herramienta**:  \n",
    "   ```python\n",
    "   if call['name'] == tool_name:\n",
    "   ```\n",
    "   - Si el `name` de la herramienta coincide con el `tool_name` especificado, se procesa.  \n",
    "\n",
    "5. **Extrae argumentos o detalles**:  \n",
    "   ```python\n",
    "   updates.append(f\"Updated {tool_name}: {call['args']}\")\n",
    "   ```\n",
    "   - Agrega un resumen como `\"Updated ToDo: {...}\"` a la lista `updates`.  \n",
    "\n",
    "6. **Devuelve los resultados**:  \n",
    "   ```python\n",
    "   return \"\\n\".join(updates) if updates else f\"No updates for {tool_name}.\"\n",
    "   ```\n",
    "   - Si hay actualizaciones, las une en una sola cadena separada por saltos de línea.  \n",
    "   - Si no se encuentran actualizaciones, devuelve `\"No updates for {tool_name}.\"`.  \n",
    "\n",
    "#### ¿Por qué es importante?\n",
    "- Esta función proporciona un **resumen claro** de las acciones realizadas por una herramienta específica durante una sesión del chatbot.  \n",
    "- Es útil para:  \n",
    "  - **Depuración**: Para ver cómo se usaron las herramientas y qué actualizaciones hicieron.  \n",
    "  - **Retroalimentación para el usuario**: Para informar a los usuarios sobre los cambios (por ejemplo, actualizaciones en la lista de tareas).  \n",
    "\n",
    "#### Ejemplo\n",
    "Supongamos que el chatbot realizó estas llamadas a herramientas:\n",
    "```python\n",
    "tool_calls = [\n",
    "    [{'name': 'ToDo', 'args': {'task': 'Buy groceries', 'status': 'done'}}],\n",
    "    [{'name': 'Profile', 'args': {'name': 'Julio', 'location': 'Madrid'}}],\n",
    "]\n",
    "```\n",
    "\n",
    "Si llamamos a:\n",
    "```python\n",
    "extract_tool_info(tool_calls, 'ToDo')\n",
    "```\n",
    "\n",
    "Devolverá:\n",
    "```\n",
    "\"Updated ToDo: {'task': 'Buy groceries', 'status': 'done'}\"\n",
    "```\n",
    "\n",
    "Si no se encontraron actualizaciones de `ToDo`, devolvería:\n",
    "```\n",
    "\"No updates for ToDo.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bbc6138-5704-4b56-8a04-43f915e4602a",
   "metadata": {},
   "source": [
    "## Explicación Línea por Línea de la Función `update_todos`\n",
    "La función `update_todos` **analiza el historial de chat** y **actualiza la lista de tareas pendientes del usuario** en el sistema de memoria a largo plazo.\n",
    "\n",
    "#### Definición de la Función\n",
    "```python\n",
    "def update_todos(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "```\n",
    "- **`state`**: Contiene el historial de conversación (mensajes entre el usuario y el chatbot).\n",
    "- **`config`**: Contiene la configuración del sistema (incluyendo el ID del usuario).\n",
    "- **`store`**: El **sistema de almacenamiento de memoria a largo plazo** donde se guardan las tareas pendientes.\n",
    "\n",
    "#### Paso 1: Obtener el ID del Usuario\n",
    "```python\n",
    "user_id = config[\"configurable\"][\"user_id\"]\n",
    "```\n",
    "- Recupera el **identificador único del usuario**.\n",
    "- Este ID se usa para **obtener y actualizar la lista de tareas pendientes del usuario**.\n",
    "\n",
    "#### Paso 2: Definir Dónde Se Almacena la Información de las Tareas\n",
    "```python\n",
    "namespace = (\"todo\", user_id)\n",
    "```\n",
    "- Define un **espacio de nombres** para almacenar **las tareas pendientes**.\n",
    "- Esto garantiza que las tareas se guarden en la categoría correcta.\n",
    "\n",
    "#### Paso 3: Recuperar la Lista de Tareas Existente\n",
    "```python\n",
    "existing_items = store.search(namespace)\n",
    "```\n",
    "- Busca en la memoria los **elementos de la lista de tareas previamente guardados**.\n",
    "- Si el usuario **ya tiene tareas**, se almacenarán en `existing_items`.\n",
    "\n",
    "#### Paso 4: Formatear las Tareas Existentes para su Procesamiento\n",
    "```python\n",
    "tool_name = \"ToDo\"\n",
    "existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                      for existing_item in existing_items]\n",
    "                      if existing_items\n",
    "                      else None\n",
    "                    )\n",
    "```\n",
    "- Si hay **tareas existentes**, se **formatean** en una lista estructurada.\n",
    "- Si **no hay tareas**, se establece en `None`.\n",
    "\n",
    "#### Paso 5: Preparar la Instrucción del Sistema\n",
    "```python\n",
    "TRUSTCALL_INSTRUCTION_FORMATTED = TRUSTCALL_INSTRUCTION.format(time=datetime.now().isoformat())\n",
    "```\n",
    "- Formatea la **plantilla de instrucciones del sistema** (`TRUSTCALL_INSTRUCTION`) insertando la **marca de tiempo actual**.\n",
    "- Esta instrucción ayuda a la IA **a procesar las actualizaciones de la lista de tareas**.\n",
    "\n",
    "#### Paso 6: Fusionar (merge) el Historial de Chat para el Análisis\n",
    "```python\n",
    "updated_messages = list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION_FORMATTED)] + state[\"messages\"][:-1]))\n",
    "```\n",
    "- **Fusiona** la **instrucción del sistema** con los mensajes recientes del usuario.\n",
    "- La función **excluye el último mensaje** en `state[\"messages\"]` porque ese mensaje es la llamada a la herramienta en sí.\n",
    "\n",
    "#### Paso 7: Inicializar un Spy (para Depuración, debugging)\n",
    "```python\n",
    "spy = Spy()\n",
    "```\n",
    "- Crea un **objeto Spy** para rastrear las llamadas a herramientas del modelo de IA.\n",
    "- Esto es útil para **depuración (debugging) y verificación de actualizaciones**.\n",
    "\n",
    "#### Paso 8: Crear el Extractor de Tareas Pendientes\n",
    "```python\n",
    "todo_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[ToDo],\n",
    "    tool_choice=tool_name,\n",
    "    enable_inserts=True\n",
    ").with_listeners(on_end=spy)\n",
    "```\n",
    "- **Crea una herramienta de IA (`todo_extractor`)** que puede:\n",
    "  - Extraer nuevas tareas de la conversación.\n",
    "  - Actualizar tareas existentes.\n",
    "  - Insertar nuevas tareas en la lista.\n",
    "- Se **adjunta el Spy** para **monitorear las actualizaciones**.\n",
    "\n",
    "#### Paso 9: Extraer Actualizaciones de la Lista de Tareas\n",
    "```python\n",
    "result = todo_extractor.invoke({\"messages\": updated_messages, \n",
    "                                \"existing\": existing_memories})\n",
    "```\n",
    "- Llama a la herramienta de IA para **analizar la conversación** e **identificar actualizaciones en la lista de tareas**.\n",
    "- Usa **las tareas previas (si existen) como contexto**.\n",
    "\n",
    "#### Paso 10: Almacenar las Tareas Actualizadas\n",
    "```python\n",
    "for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "    store.put(namespace,\n",
    "              rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "              r.model_dump(mode=\"json\"),\n",
    "    )\n",
    "```\n",
    "- **Recorre las actualizaciones de tareas extraídas**.\n",
    "- **Guarda la lista de tareas actualizada** en la memoria.\n",
    "- Si una tarea **no tiene un ID**, se genera un **UUID** (identificador único).\n",
    "\n",
    "#### Paso 11: Recuperar la Llamada Original a la Herramienta\n",
    "```python\n",
    "tool_calls = state['messages'][-1].tool_calls\n",
    "```\n",
    "- Recupera el **ID de la llamada original a la herramienta** para vincular la actualización con la solicitud correcta.\n",
    "\n",
    "#### Paso 12: Extraer y Resumir las Actualizaciones\n",
    "```python\n",
    "todo_update_msg = extract_tool_info(spy.called_tools, tool_name)\n",
    "```\n",
    "- Usa la función `extract_tool_info` para **resumir qué cambios se realizaron**.\n",
    "- Esto asegura que el chatbot **pueda informar al usuario sobre la actualización**.\n",
    "\n",
    "#### Paso 13: Devolver un Mensaje de Confirmación\n",
    "```python\n",
    "return {\"messages\": [{\"role\": \"tool\", \"content\": todo_update_msg, \"tool_call_id\": tool_calls[0]['id']}]}\n",
    "```\n",
    "- **Devuelve una respuesta** confirmando la actualización de la lista de tareas.\n",
    "- Esto **notifica al chatbot** que la actualización de la tarea fue exitosa.\n",
    "\n",
    "#### Resumen de lo que Hace `update_todos`\n",
    "1. **Recupera la lista de tareas del usuario** (si existe).\n",
    "2. **Formatea las tareas existentes** para que la IA (el modelo LLM) pueda procesarlas.\n",
    "3. **Prepara una instrucción del sistema** para analizar las actualizaciones de tareas.\n",
    "4. **Fusiona el historial reciente de chat** para dar contexto.\n",
    "5. **Utiliza una herramienta de IA para extraer actualizaciones de la lista de tareas**.\n",
    "6. **Guarda las tareas actualizadas** en la memoria a largo plazo.\n",
    "7. **Resume los cambios** para el chatbot.\n",
    "8. **Devuelve un mensaje de confirmación** indicando que la actualización fue exitosa.\n",
    "\n",
    "Esta función garantiza que el chatbot **recuerde y actualice las tareas del usuario** de manera efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f02b3-b9d1-41bf-b976-dae31310375d",
   "metadata": {},
   "source": [
    "## Explicación Línea por Línea de la Función `update_instructions`\n",
    "La función `update_instructions` **analiza el historial de chat** y **actualiza las preferencias del usuario** sobre cómo debe gestionarse su lista de tareas pendientes.\n",
    "\n",
    "#### Definición de la Función\n",
    "```python\n",
    "def update_instructions(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "```\n",
    "- **`state`**: Contiene el historial de conversación (mensajes entre el usuario y el chatbot).\n",
    "- **`config`**: Incluye la configuración del sistema (como el ID del usuario).\n",
    "- **`store`**: El **almacenamiento de memoria a largo plazo** donde se guardan las preferencias del usuario.\n",
    "\n",
    "#### Paso 1: Obtener el ID del Usuario\n",
    "```python\n",
    "user_id = config[\"configurable\"][\"user_id\"]\n",
    "```\n",
    "- Recupera el **identificador único del usuario**.\n",
    "- Este ID se usa para **obtener y actualizar las preferencias del usuario** sobre su lista de tareas pendientes.\n",
    "\n",
    "#### Paso 2: Definir Dónde Se Almacenan las Preferencias de Tareas\n",
    "```python\n",
    "namespace = (\"instructions\", user_id)\n",
    "```\n",
    "- Define un **espacio de nombres** para almacenar **las preferencias de gestión de tareas**.\n",
    "- Esto garantiza que las **preferencias se guarden en la categoría correcta**.\n",
    "\n",
    "#### Paso 3: Recuperar las Preferencias Existentes del Usuario\n",
    "```python\n",
    "existing_memory = store.get(namespace, \"user_instructions\")\n",
    "```\n",
    "- Busca en la **memoria de almacenamiento** si hay **instrucciones previas guardadas** sobre cómo el usuario prefiere gestionar sus tareas.\n",
    "- Si el usuario **ha proporcionado preferencias antes**, estas se guardan en `existing_memory`.\n",
    "\n",
    "#### Paso 4: Formatear las Preferencias Actuales\n",
    "```python\n",
    "system_msg = CREATE_INSTRUCTIONS.format(current_instructions=existing_memory.value if existing_memory else None)\n",
    "```\n",
    "- Usa una **plantilla (`CREATE_INSTRUCTIONS`)** para **generar un mensaje del sistema**.\n",
    "- Inserta **las preferencias existentes** (si hay alguna) o establece `None` si no existen.\n",
    "- Este mensaje del sistema **guía a la IA (el modelo LLM) sobre cómo debe procesar las instrucciones del usuario**.\n",
    "\n",
    "#### Paso 5: Generar Instrucciones Actualizadas\n",
    "```python\n",
    "new_memory = model.invoke([SystemMessage(content=system_msg)] + state['messages'][:-1] + [HumanMessage(content=\"Please update the instructions based on the conversation\")])\n",
    "```\n",
    "- Envía **una solicitud al modelo de IA (`gpt-4o`)** para:\n",
    "  - Analizar el **historial de conversación**.\n",
    "  - Comprender **cómo el usuario quiere gestionar sus tareas**.\n",
    "  - Generar **instrucciones actualizadas** basadas en la conversación.\n",
    "- **Cómo funciona:**\n",
    "  - Se envía primero el **mensaje del sistema** (con las instrucciones antiguas).\n",
    "  - Luego se añade el **historial de chat del usuario**.\n",
    "  - Un mensaje final **pide explícitamente a la IA que actualice las instrucciones**.\n",
    "\n",
    "#### Paso 6: Guardar las Preferencias Actualizadas\n",
    "```python\n",
    "key = \"user_instructions\"\n",
    "store.put(namespace, key, {\"memory\": new_memory.content})\n",
    "```\n",
    "- Guarda las **instrucciones actualizadas** en el almacenamiento de memoria bajo la clave `\"user_instructions\"`.\n",
    "\n",
    "#### Paso 7: Recuperar la Llamada Original a la Herramienta\n",
    "```python\n",
    "tool_calls = state['messages'][-1].tool_calls\n",
    "```\n",
    "- Recupera el **ID de la llamada original a la herramienta** para vincular la actualización con la solicitud correcta.\n",
    "\n",
    "#### Paso 8: Devolver un Mensaje de Confirmación\n",
    "```python\n",
    "return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated instructions\", \"tool_call_id\": tool_calls[0]['id']}]}\n",
    "```\n",
    "- Devuelve una **respuesta de confirmación** indicando que **las instrucciones han sido actualizadas**.\n",
    "- Esto asegura que el chatbot **reconozca la actualización** y continúe funcionando con las nuevas preferencias.\n",
    "\n",
    "#### Resumen de lo que Hace `update_instructions`\n",
    "1. **Recupera las preferencias del usuario** sobre su lista de tareas (si existen).\n",
    "2. **Formatea un mensaje del sistema** con las preferencias actuales.\n",
    "3. **Fusiona el historial de chat reciente** para proporcionar contexto.\n",
    "4. **Solicita al modelo de IA que genere instrucciones actualizadas**.\n",
    "5. **Guarda las instrucciones actualizadas** en la memoria a largo plazo.\n",
    "6. **Devuelve un mensaje de confirmación** indicando que la actualización fue exitosa.\n",
    "\n",
    "Esta función garantiza que el chatbot **se adapte a cómo el usuario quiere que se gestionen sus tareas**, haciendo las interacciones más personalizadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c95a75-584d-480c-92e5-5f71dadf23c2",
   "metadata": {},
   "source": [
    "## Bien. Ahora revisemos el segmento donde definimos el Router\n",
    "\n",
    "Este segmento del código define una **función de toma de decisiones** llamada `route_message`. Su objetivo es **analizar el último mensaje del usuario** y **decidir qué acción debe tomar el chatbot a continuación**.\n",
    "\n",
    "#### Propósito\n",
    "La función **dirige el flujo de la conversación** según el tipo de información detectada en el mensaje del usuario (por ejemplo, una actualización del perfil, una actualización de tareas o una actualización de instrucciones).\n",
    "\n",
    "#### Qué Hace\n",
    "\n",
    "1. **Verifica el Último Mensaje:**  \n",
    "   - Recupera el **último mensaje** del historial de chat (`state['messages'][-1]`).  \n",
    "   - Busca si hay **llamadas a herramientas** (acciones especiales activadas por el chatbot; en este caso, los tres tipos de actualizaciones).  \n",
    "\n",
    "2. **¿No Hay Llamadas a Herramientas? Finaliza el Proceso:**  \n",
    "   - Si el mensaje **no contiene llamadas a herramientas** (es decir, no hay solicitud de actualización), **finaliza** el proceso (`return END`).  \n",
    "   - Esto significa que no se necesita actualizar la memoria, y el chatbot simplemente continúa la conversación.  \n",
    "\n",
    "3. **Identifica el Tipo de Llamada a Herramienta:**  \n",
    "   - Si el mensaje **sí contiene llamadas a herramientas**, verifica **qué tipo de actualización** se ha solicitado.  \n",
    "\n",
    "4. **Decide la Próxima Acción:**  \n",
    "   Según el **tipo de actualización** detectado:\n",
    "   - `\"user\"` → Se actualiza el **perfil del usuario** (`return \"update_profile\"`).  \n",
    "   - `\"todo\"` → Se actualiza la **lista de tareas pendientes** (`return \"update_todos\"`).  \n",
    "   - `\"instructions\"` → Se actualizan las **instrucciones** (`return \"update_instructions\"`).  \n",
    "   - **De lo contrario:** Si el tipo de actualización **no es reconocido**, se lanza un **error** (`ValueError`).  \n",
    "\n",
    "#### Cómo Se Integra en el Flujo de Trabajo\n",
    "\n",
    "- Esta función actúa como un **director de tráfico** para el chatbot.  \n",
    "- Después de analizar el mensaje del usuario, **decide qué función (nodo) ejecutar a continuación**:\n",
    "  - **Actualizaciones de perfil** → `update_profile`.  \n",
    "  - **Actualizaciones de la lista de tareas** → `update_todos`.  \n",
    "  - **Actualizaciones de instrucciones** → `update_instructions`.  \n",
    "  - **Si no hay nada que actualizar** → Finaliza el proceso.  \n",
    "\n",
    "#### Ejemplo de Flujo de Trabajo\n",
    "\n",
    "**Mensaje del Usuario:**  \n",
    "*\"Necesito añadir 'Entregar informe de impuestos' a mis tareas y actualizar mi ubicación a Madrid.\"*  \n",
    "\n",
    "**Paso a Paso:**\n",
    "1. El chatbot detecta **dos llamadas a herramientas**:  \n",
    "   - **Actualizar lista de tareas** (tarea: \"Entregar informe de impuestos\").  \n",
    "   - **Actualizar perfil** (ubicación: \"Madrid\").  \n",
    "\n",
    "2. La primera llamada a herramienta (`\"todo\"`) se procesa → **route_message** dirige el flujo a `update_todos`.  \n",
    "\n",
    "3. Una vez que se actualiza la lista de tareas, el chatbot **vuelve a ejecutar** la función y procesa la siguiente llamada a herramienta (`\"user\"`), dirigiéndola a `update_profile`.  \n",
    "\n",
    "4. Después de procesar ambas actualizaciones, el chatbot **retoma la conversación** con el usuario.  \n",
    "\n",
    "#### Conclusiones Clave\n",
    "\n",
    "- **Decide el Siguiente Paso:**  \n",
    "  Dirige al chatbot para manejar **actualizaciones de perfil, tareas o instrucciones** según el mensaje del usuario.  \n",
    "\n",
    "- **Flexible y Contextual:**  \n",
    "  Permite que el chatbot **responda dinámicamente** a múltiples tipos de actualizaciones sin necesidad de comandos predefinidos.  \n",
    "\n",
    "- **Manejo de Errores:**  \n",
    "  Lanza un error si se detecta un **tipo de actualización desconocido**, asegurando **integridad en los datos**.  \n",
    "\n",
    "Esta función hace que el chatbot sea **inteligente y adaptable**, permitiéndole realizar **procesos de múltiples pasos** dentro de una misma conversación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a8f0d-218c-4a95-8cf2-d863ee18181c",
   "metadata": {},
   "source": [
    "## Explicación Línea por Línea de la Función `route_message`\n",
    "\n",
    "La función `route_message` es una **función de decisión condicional** dentro del flujo de LangGraph, lo que significa que **determina el siguiente paso en el flujo de trabajo** según la última interacción del usuario.\n",
    "\n",
    "#### Definición de la Función\n",
    "```python\n",
    "def route_message(state: MessagesState, config: RunnableConfig, store: BaseStore) -> Literal[END, \"update_todos\", \"update_instructions\", \"update_profile\"]:\n",
    "```\n",
    "- Esta función **recibe tres argumentos**:\n",
    "  - `state`: El state actual de la conversación (contiene el historial de mensajes).\n",
    "  - `config`: Configuración para la ejecución del flujo en LangGraph.\n",
    "  - `store`: Un sistema de almacenamiento donde se mantiene la memoria a largo plazo.\n",
    "- La función **devuelve uno de los cuatro valores posibles**:\n",
    "  - `\"update_profile\"` → Si se necesita actualizar la información del perfil del usuario.\n",
    "  - `\"update_todos\"` → Si se requiere una actualización en la lista de tareas pendientes.\n",
    "  - `\"update_instructions\"` → Si es necesario modificar las preferencias del usuario sobre la gestión de tareas.\n",
    "  - `END` → Si no se necesita ninguna actualización, el proceso finaliza.\n",
    "\n",
    "#### Paso 1: Obtener el Último Mensaje del Usuario\n",
    "```python\n",
    "message = state['messages'][-1]\n",
    "```\n",
    "- Recupera el **último mensaje** del historial de conversación.\n",
    "- Este mensaje es la base para decidir **qué acción tomar a continuación**.\n",
    "\n",
    "#### Paso 2: Verificar si Hay Llamadas a Herramientas\n",
    "```python\n",
    "if len(message.tool_calls) == 0:\n",
    "    return END\n",
    "```\n",
    "- Si **no hay llamadas a herramientas** en el último mensaje, **no hay nada que actualizar**, por lo que la función **finaliza el proceso** devolviendo `END`.\n",
    "\n",
    "#### Paso 3: Obtener la Primera Llamada a Herramienta\n",
    "```python\n",
    "else:\n",
    "    tool_call = message.tool_calls[0]\n",
    "```\n",
    "- Si hay **llamadas a herramientas** (es decir, se requiere una actualización), la función **toma la primera** para procesarla.\n",
    "\n",
    "#### Paso 4: Determinar el Tipo de Actualización\n",
    "```python\n",
    "if tool_call['args']['update_type'] == \"user\":\n",
    "    return \"update_profile\"\n",
    "```\n",
    "- Si el tipo de actualización es `\"user\"`, la función **redirige el flujo a `update_profile`**.\n",
    "- Esto significa que se necesita actualizar el **perfil del usuario** (nombre, ocupación, intereses, etc.).\n",
    "\n",
    "```python\n",
    "elif tool_call['args']['update_type'] == \"todo\":\n",
    "    return \"update_todos\"\n",
    "```\n",
    "- Si el tipo de actualización es `\"todo\"`, la función **redirige el flujo a `update_todos`**.\n",
    "- Esto indica que la **lista de tareas pendientes del usuario** requiere una actualización (agregar, modificar o eliminar una tarea).\n",
    "\n",
    "```python\n",
    "elif tool_call['args']['update_type'] == \"instructions\":\n",
    "    return \"update_instructions\"\n",
    "```\n",
    "- Si el tipo de actualización es `\"instructions\"`, la función **redirige el flujo a `update_instructions`**.\n",
    "- Esto indica que se deben actualizar **las preferencias del usuario sobre la gestión de tareas**.\n",
    "\n",
    "#### Paso 5: Manejar Casos No Esperados\n",
    "```python\n",
    "else:\n",
    "    raise ValueError\n",
    "```\n",
    "- Si el `update_type` no coincide con `\"user\"`, `\"todo\"` o `\"instructions\"`, **se lanza un error**.\n",
    "- Esto evita comportamientos inesperados si la IA (el modelo LLM) o el usuario proporcionan una solicitud inválida.\n",
    "\n",
    "#### Resumen de lo que Hace `route_message`\n",
    "1. **Verifica el último mensaje del usuario**.\n",
    "2. **Si no se necesita una actualización**, finaliza el proceso (`END`).\n",
    "3. **Si se necesita una actualización**, examina el tipo de llamada a herramienta:\n",
    "   - `\"user\"` → Actualiza el perfil del usuario (`update_profile`).\n",
    "   - `\"todo\"` → Actualiza la lista de tareas (`update_todos`).\n",
    "   - `\"instructions\"` → Actualiza las preferencias de gestión de tareas (`update_instructions`).\n",
    "4. **Si se encuentra un tipo de actualización no válido**, lanza un error.\n",
    "\n",
    "#### ¿Por qué es Importante esta Función?\n",
    "- **Encamina correctamente las actualizaciones** en la memoria del chatbot.\n",
    "- **Optimiza el flujo de conversación**, permitiendo que el chatbot responda dinámicamente a diferentes necesidades del usuario.\n",
    "- **Previene errores** asegurando que solo se procesen tipos de actualización válidos.\n",
    "\n",
    "Esta función garantiza que el chatbot **maneje de forma eficiente las interacciones del usuario** y actualice la información según sea necesario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31764b27-fcdd-4096-8e97-dd0bee9af4a1",
   "metadata": {},
   "source": [
    "## Finalmente, revisemos el Segmento donde Definimos el Flujo del Agente.\n",
    "\n",
    "Este segmento del código **crea y configura una estructura similar a un diagrama de flujo** (un **graph**) para controlar cómo el chatbot procesa y actualiza su memoria. Define los **pasos** (nodos) y las **conexiones** (edges) entre ellos, guiando la toma de decisiones del chatbot.\n",
    "\n",
    "#### Construcción del Graph (StateGraph)\n",
    "```python\n",
    "builder = StateGraph(MessagesState)\n",
    "```\n",
    "- **Propósito:** Configura una **estructura de graph** para gestionar las acciones del chatbot.  \n",
    "- **`MessagesState`:** Mantiene el state **actual de los mensajes** durante la conversación.\n",
    "\n",
    "#### Añadir Nodos\n",
    "```python\n",
    "builder.add_node(task_mAIstro)\n",
    "builder.add_node(update_todos)\n",
    "builder.add_node(update_profile)\n",
    "builder.add_node(update_instructions)\n",
    "```\n",
    "- **Los nodos representan las acciones** que el chatbot puede realizar.  \n",
    "- Se añaden 4 nodos al graph:\n",
    "  1. **`task_mAIstro`:** Analiza el mensaje del usuario y decide qué actualizar.  \n",
    "  2. **`update_todos`:** Actualiza la **lista de tareas pendientes**.  \n",
    "  3. **`update_profile`:** Actualiza el **perfil del usuario**.  \n",
    "  4. **`update_instructions`:** Modifica las **preferencias de gestión de tareas** del usuario.\n",
    "\n",
    "#### Conectar los Nodos (Flujo de Trabajo)\n",
    "\n",
    "**Inicio del Proceso**\n",
    "```python\n",
    "builder.add_edge(START, \"task_mAIstro\")\n",
    "```\n",
    "- El flujo comienza en **`task_mAIstro`**, que analiza el mensaje del usuario y **decide qué hacer a continuación**.\n",
    "\n",
    "**Tomar Decisiones**\n",
    "```python\n",
    "builder.add_conditional_edges(\"task_mAIstro\", route_message)\n",
    "```\n",
    "- **`route_message`:** Actúa como un **controlador de tráfico**, dirigiendo el flujo según el contenido del mensaje del usuario.  \n",
    "  - Si el usuario menciona una tarea → Ir a **`update_todos`**.  \n",
    "  - Si el usuario proporciona información personal → Ir a **`update_profile`**.  \n",
    "  - Si el usuario especifica preferencias → Ir a **`update_instructions`**.  \n",
    "  - Si no hay nada que actualizar → **Finaliza el proceso**.\n",
    "\n",
    "**Volver al Inicio para Procesar Más Actualizaciones**\n",
    "```python\n",
    "builder.add_edge(\"update_todos\", \"task_mAIstro\")\n",
    "builder.add_edge(\"update_profile\", \"task_mAIstro\")\n",
    "builder.add_edge(\"update_instructions\", \"task_mAIstro\")\n",
    "```\n",
    "- Después de **actualizar la memoria**, el chatbot **vuelve al inicio** para **procesar más mensajes**, si es necesario.  \n",
    "- Este **comportamiento en bucle** permite que el chatbot **maneje múltiples actualizaciones** en una sola sesión.\n",
    "\n",
    "#### Configurar el Almacenamiento de Memoria\n",
    "\n",
    "**Memoria a Largo Plazo**\n",
    "```python\n",
    "across_thread_memory = InMemoryStore()\n",
    "```\n",
    "- Almacena **datos a largo plazo**, como el **perfil del usuario, la lista de tareas y las preferencias**.  \n",
    "- Permite que el chatbot **recuerde interacciones pasadas** entre sesiones de conversación.\n",
    "\n",
    "**Memoria a Corto Plazo**\n",
    "```python\n",
    "within_thread_memory = MemorySaver()\n",
    "```\n",
    "- Rastrea **datos temporales** durante la **sesión de chat actual**.  \n",
    "- Útil para **procesar múltiples llamadas a herramientas** dentro de una sola conversación.\n",
    "\n",
    "#### Compilar el Graph\n",
    "```python\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "```\n",
    "- **Compila el graph** en un **flujo funcional para el chatbot**.  \n",
    "- **Conecta el almacenamiento de memoria** al chatbot, permitiéndole **recuperar y actualizar datos** según sea necesario.\n",
    "\n",
    "#### ¿Cómo Funciona Este Graph?\n",
    "\n",
    "**Ejemplo de Flujo de Trabajo**\n",
    "**Mensaje del Usuario:**  \n",
    "*\"Necesito terminar mi informe para el viernes y mi nombre es Alicia.\"*  \n",
    "\n",
    "1. Comienza en **`task_mAIstro`** → Analiza el mensaje del usuario.  \n",
    "2. Ruta hacia **`update_todos`** → Agrega la tarea \"Terminar informe para el viernes\". \n",
    "3. Vuelve a ejecutarse → Ruta hacia **`update_profile`** → Actualiza el nombre a \"Alicia\".  \n",
    "4. Vuelve a ejecutarse nuevamente → Finaliza el proceso porque no hay más actualizaciones pendientes.\n",
    "\n",
    "#### Conclusiones Clave\n",
    "- El **graph** funciona como un **mapa** que controla cómo el chatbot **procesa la información del usuario y actualiza la memoria**.  \n",
    "- **Permite manejar múltiples actualizaciones** en una sola sesión al regresar al nodo principal después de cada cambio.  \n",
    "- **La memoria a largo plazo** guarda información persistente, mientras que **la memoria a corto plazo** gestiona la sesión en curso.  \n",
    "- Este diseño hace que el chatbot sea **flexible, consciente del contexto y capaz de aprender** a medida que la conversación evoluciona."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be64b3d-e626-453b-9661-772624a11e88",
   "metadata": {},
   "source": [
    "## ¡Wow, eso ha sido un repaso detallado! Visto eso, ahora ya podemos ver al Agente en acción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f58973-5785-45cc-8363-272f8526006a",
   "metadata": {},
   "source": [
    "## Comencemos nuestra conversación con el ToDo Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b7e80af-cbdc-4954-b05a-2b2a69df5c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "My name is Julio. I live in San Francisco.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_naNKe8eiOKIhLVpk7RCQPqA4)\n",
      " Call ID: call_naNKe8eiOKIhLVpk7RCQPqA4\n",
      "  Args:\n",
      "    update_type: user\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated profile\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello, Julio! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"Julio\"}}\n",
    "\n",
    "# User input to create a profile memory\n",
    "input_messages = [HumanMessage(content=\"My name is Julio. I live in San Francisco.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4da7f4-004f-49b9-a810-8e287b84cc76",
   "metadata": {},
   "source": [
    "## Expliquemos en términos sencillos lo que acabamos de hacer\n",
    "\n",
    "El código anterior demuestra cómo utilizar el sistema de memoria descrito previamente para procesar la entrada (input) del usuario y actualizar la memoria del chatbot. Aquí tienes un desglose en términos simples:\n",
    "\n",
    "#### ¿Qué está haciendo?\n",
    "\n",
    "1. **Preparar la configuración**\n",
    "   - Se crea un diccionario `config` con dos identificadores:\n",
    "     - **`thread_id`**: Representa la sesión actual o \"memoria a corto plazo\".\n",
    "     - **`user_id`**: Identifica al usuario (en este caso, \"Julio\") para la \"memoria a largo plazo\".\n",
    "\n",
    "2. **Proporcionar entrada (input) del usuario**\n",
    "   - La lista `input_messages` contiene la entrada del usuario.\n",
    "   - En este caso, Julio comparte detalles personales: `\"Me llamo Julio. Vivo en San Francisco.\"`\n",
    "\n",
    "3. **Ejecutar el graph**\n",
    "   - La función `graph.stream` procesa los mensajes de entrada y actualiza el sistema de memoria del chatbot según el flujo de trabajo definido.\n",
    "\n",
    "4. **Transmitir resultados**\n",
    "   - El `stream_mode=\"values\"` garantiza que el graph emita resultados intermedios mientras procesa la entrada.\n",
    "   - Para cada \"fragmento\" (paso del procesamiento), el último mensaje en `chunk[\"messages\"]` se imprime en un formato legible utilizando `pretty_print()`.\n",
    "\n",
    "\n",
    "#### ¿Cómo funciona en la práctica?\n",
    "1. **La entrada (input) del usuario se pasa al graph**:\n",
    "   - Los nodos del gráfico (como `task_mAIstro`, `update_profile`, etc.) procesan el mensaje de entrada.\n",
    "   - Determina que la entrada del usuario contiene información personal (nombre y ubicación).\n",
    "\n",
    "2. **Actualización de la memoria**:\n",
    "   - Se activa el nodo `update_profile` porque la entrada es relevante para el perfil del usuario.\n",
    "   - Se crea una nueva entrada en la memoria para \"Julio\" con su nombre y ubicación.\n",
    "\n",
    "3. **Mostrar los resultados**:\n",
    "   - La memoria actualizada o la respuesta del chatbot se transmite y se muestra utilizando `pretty_print()`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf3b04f-8c53-47bc-9026-68ec3bf11a6a",
   "metadata": {},
   "source": [
    "## Bien. Ahora añadamos nuestra primera tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6cfe3ef8-ebd6-44ef-8eb3-110c21fa8c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Schedule interviews with candidates for California Sales Manager.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_lqjYq0pgzgoSlvTMLyAknKsy)\n",
      " Call ID: call_lqjYq0pgzgoSlvTMLyAknKsy\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Updated ToDo: {'task': 'Schedule interviews with candidates for California Sales Manager.', 'time_to_complete': 120, 'solutions': ['Use scheduling software like Calendly or Doodle to coordinate times.', 'Contact candidates via email or phone to confirm availability.', 'Coordinate with the hiring team to ensure their availability.'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added \"Schedule interviews with candidates for California Sales Manager\" to your ToDo list. Is there anything else you'd like to add or update?\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [HumanMessage(content=\"Schedule interviews with candidates for California Sales Manager.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5810f056-c1d2-4d95-a97d-7e51567e6086",
   "metadata": {},
   "source": [
    "## Observa cómo eso ha actualizado la memoria de tareas pendientes. Esto es lo que hemos hecho.\n",
    "\n",
    "El código anterior demuestra cómo el chatbot procesa un mensaje del usuario relacionado con una tarea y actualiza la **lista de tareas pendientes** en su memoria. Aquí tienes una explicación simplificada:\n",
    "\n",
    "#### ¿Qué hace este código?\n",
    "\n",
    "1. **Entrada (input) del usuario para una tarea**\n",
    "   - El usuario proporciona un nuevo mensaje:  \n",
    "     `\"Programar entrevistas con candidatos para el puesto de Gerente de Ventas en California.\"`\n",
    "   - Esto se interpreta como una tarea que el chatbot debe agregar a su **lista de tareas pendientes**.\n",
    "\n",
    "2. **Ejecutar el graph**\n",
    "   - La función `graph.stream` procesa el mensaje de entrada (input).\n",
    "   - Utiliza el flujo de trabajo definido en el graph (por ejemplo, nodos como `task_mAIstro` y `update_todos`) para decidir cómo manejar la entrada.\n",
    "\n",
    "3. **Actualizar la lista de tareas**\n",
    "   - El flujo de trabajo identifica que esta entrada (input) está relacionada con una tarea.\n",
    "   - Se activa el nodo `update_todos`, que actualiza la **lista de tareas pendientes** del usuario en memoria añadiendo la nueva tarea.\n",
    "\n",
    "4. **Transmitir los resultados**\n",
    "   - A medida que el gráfico procesa la entrada, transmite resultados intermedios con `stream_mode=\"values\"`.\n",
    "   - En cada paso del procesamiento, el último mensaje se muestra en un formato amigable usando `pretty_print()`.\n",
    "\n",
    "\n",
    "#### ¿Cómo funciona?\n",
    "\n",
    "1. **Analizar la entrada (input)**:\n",
    "   - El chatbot reconoce que la entrada describe una tarea y no información personal o preferencias.\n",
    "\n",
    "2. **Decidir actualizar la lista de tareas**:\n",
    "   - El sistema dirige la entrada al nodo `update_todos`.\n",
    "   - Este nodo añade la tarea a la memoria de la **lista de tareas pendientes** bajo el ID del usuario (`Julio`).\n",
    "\n",
    "3. **Proporcionar retroalimentación**:\n",
    "   - El chatbot puede confirmar la adición de la tarea generando una respuesta como:  \n",
    "     ```\n",
    "     \"He añadido 'Programar entrevistas con candidatos para el puesto de Gerente de Ventas en California' a tu lista de tareas pendientes.\"\n",
    "     ```\n",
    "\n",
    "4. **Guardar en memoria**:\n",
    "   - La tarea se almacena en la memoria a largo plazo para que pueda ser recuperada o actualizada más adelante."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87106b5-b8df-4b1e-8281-d4a90fd8bef7",
   "metadata": {},
   "source": [
    "## Bien. Ahora indiquemos al Agente cómo comportarse y veamos si eso actualiza la memoria de instrucciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b475d4e1-839d-44c5-8928-a43d3d82a14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "When creating or updating ToDo items, include if they are urgent or non-urgent. If I do not said anything about this matter, assume the task is not urgent.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_ZRFF0RPJTJjQVnM2R0sHWMJ4)\n",
      " Call ID: call_ZRFF0RPJTJjQVnM2R0sHWMJ4\n",
      "  Args:\n",
      "    update_type: instructions\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated instructions\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Got it! I'll make sure to include whether tasks are urgent or non-urgent, and if you don't specify, I'll assume they're not urgent. How else can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# User input to update instructions for creating ToDos\n",
    "input_messages = [HumanMessage(content=\"When creating or updating ToDo items, include if they are urgent or non-urgent. If I do not said anything about this matter, assume the task is not urgent.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e583e5c-8b08-4f12-b6cc-1ea2c89f524b",
   "metadata": {},
   "source": [
    "## Eso funcionó bien. Veamos qué acabamos de hacer.\n",
    "\n",
    "El código anterior demuestra cómo el chatbot procesa un mensaje del usuario para actualizar **instrucciones** sobre la gestión de su **lista de tareas pendientes**. Aquí tienes una explicación sencilla:\n",
    "\n",
    "#### ¿Qué hace el código?\n",
    "\n",
    "1. **Entrada (input) del usuario para actualizar instrucciones**  \n",
    "   - El usuario proporciona una preferencia específica:  \n",
    "     ```\n",
    "     \"Al crear o actualizar elementos de la lista de tareas, indica si son urgentes o no urgentes. Si no digo nada al respecto, asume que la tarea no es urgente.\"\n",
    "     ```\n",
    "   - Esta instrucción le dice al chatbot cómo manejar la urgencia al gestionar tareas en la lista de pendientes.\n",
    "\n",
    "2. **Ejecutar el gráfico**  \n",
    "   - La función `graph.stream` procesa el mensaje.  \n",
    "   - Utiliza el flujo de trabajo definido en el gráfico para determinar que la entrada está relacionada con **instrucciones** sobre la gestión de la **lista de tareas pendientes**.\n",
    "\n",
    "3. **Actualizar las instrucciones**  \n",
    "   - El flujo de trabajo identifica que esta entrada especifica preferencias del usuario sobre cómo manejar las tareas.  \n",
    "   - Se activa el nodo `update_instructions`, que actualiza la memoria del chatbot con las nuevas **instrucciones** proporcionadas por el usuario.\n",
    "\n",
    "4. **Transmitir resultados**  \n",
    "   - El gráfico procesa la entrada por etapas y transmite los resultados intermedios utilizando `stream_mode=\"values\"`.  \n",
    "   - El último mensaje se muestra con `pretty_print()`, proporcionando un resumen legible de lo que hizo el chatbot.\n",
    "\n",
    "\n",
    "#### ¿Cómo funciona?\n",
    "\n",
    "1. **Analizar la entrada (input)**  \n",
    "   - El chatbot reconoce que la entrada contiene nuevas instrucciones sobre la gestión de tareas, en lugar de información personal o tareas específicas.\n",
    "\n",
    "2. **Decidir actualizar las instrucciones**  \n",
    "   - El sistema dirige la entrada al nodo `update_instructions`.  \n",
    "   - Este nodo actualiza la **memoria de instrucciones** del usuario (`Julio`) con la nueva preferencia sobre la urgencia de las tareas.\n",
    "\n",
    "3. **Guardar y aplicar la actualización**  \n",
    "   - Las instrucciones actualizadas se almacenan en la memoria, reemplazando o agregando a las anteriores.  \n",
    "   - El chatbot no informa explícitamente al usuario sobre los cambios en las instrucciones (según su diseño), pero aplicará estas nuevas reglas en futuras interacciones.\n",
    "\n",
    "\n",
    "Aunque en este caso puede que no haya una respuesta directa al usuario, el chatbot ahora utilizará esta nueva instrucción al gestionar tareas. Por ejemplo, si más adelante el usuario dice:  \n",
    "`\"Añadir 'Preparar una presentación' a mi lista de tareas pendientes,\"`  \n",
    "el chatbot marcará automáticamente la tarea como **no urgente**, a menos que el usuario especifique lo contrario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b49764-8d0b-4038-988d-bf809e836bbe",
   "metadata": {},
   "source": [
    "## Veamos la memoria de instrucciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6c4ead5-082e-4028-b477-fabc25ffb563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'memory': '<current_instructions>\\nWhen creating or updating ToDo items, include if they are urgent or non-urgent. If the user does not specify, assume the task is not urgent.\\n</current_instructions>'}\n"
     ]
    }
   ],
   "source": [
    "# Check for updated instructions\n",
    "user_id = \"Julio\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"instructions\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279852b0-b3b9-4767-99ac-ba1925c1b253",
   "metadata": {},
   "source": [
    "## ¿Has visto? La memoria de instrucciones ahora está actualizada. Revisemos lo que acabamos de hacer.\n",
    "\n",
    "El código anterior se utiliza para **recuperar y visualizar las instrucciones actualizadas** almacenadas en la memoria del chatbot para un usuario específico (`Julio`). Aquí tienes una explicación sencilla:\n",
    "\n",
    "#### ¿Qué hace el código?\n",
    "\n",
    "1. **Especificar el usuario**  \n",
    "   - La variable `user_id` se establece en `\"Julio\"`, lo que indica que queremos recuperar las instrucciones asociadas con él.\n",
    "\n",
    "2. **Buscar las instrucciones**  \n",
    "   - La función `across_thread_memory.search` se usa para buscar elementos de memoria almacenados bajo el espacio de nombres **\"instructions\"** para el usuario con ID `\"Julio\"`.  \n",
    "   - `(\"instructions\", user_id)` actúa como una etiqueta para identificar el conjunto específico de instrucciones en la memoria.\n",
    "\n",
    "3. **Imprimir los resultados**  \n",
    "   - Para cada elemento de memoria encontrado, el código imprime su `value`, que contiene las instrucciones almacenadas en la memoria.\n",
    "\n",
    "\n",
    "#### ¿Cómo funciona?\n",
    "\n",
    "- **Búsqueda en la memoria**: El objeto `across_thread_memory` almacena la memoria a largo plazo (datos persistentes entre sesiones o hilos de conversación).  \n",
    "- **Filtrado por espacio de nombres**: La búsqueda se centra específicamente en las entradas de memoria dentro de la categoría `\"instructions\"` para Julio.  \n",
    "- **Acceso a los datos almacenados**: El atributo `memory.value` recupera el contenido (las instrucciones) almacenadas en la memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576b46f1-ea57-4322-a6d0-39e3fef8db36",
   "metadata": {},
   "source": [
    "## OK. Añadamos una segunda tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f300e149-5559-4556-bfc4-bde938c23f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Schedule monthly meeting with the USA Sales Team.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_dQk57bOe9oHQlhcULLNHuFwh)\n",
      " Call ID: call_dQk57bOe9oHQlhcULLNHuFwh\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Updated ToDo: {'task': 'Schedule monthly meeting with the USA Sales Team.', 'time_to_complete': 60, 'solutions': ['Use a recurring calendar event to schedule the meeting.', 'Ensure all team members are available at the chosen time.', 'Prepare an agenda in advance.'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added \"Schedule monthly meeting with the USA Sales Team\" to your ToDo list. Let me know if there's anything else you need help with!\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [HumanMessage(content=\"Schedule monthly meeting with the USA Sales Team.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d4cb02-8915-44a2-b449-ec8990f4cdb5",
   "metadata": {},
   "source": [
    "## ¿Cómo puedes ver una lista de todas las tareas pendientes? Mira:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae394955-7707-4244-adfe-2afba10a9763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'Schedule interviews with candidates for California Sales Manager.', 'time_to_complete': 120, 'deadline': None, 'solutions': ['Use scheduling software like Calendly or Doodle to coordinate times.', 'Contact candidates via email or phone to confirm availability.', 'Coordinate with the hiring team to ensure their availability.'], 'status': 'not started'}\n",
      "{'task': 'Schedule monthly meeting with the USA Sales Team.', 'time_to_complete': 60, 'deadline': None, 'solutions': ['Use a recurring calendar event to schedule the meeting.', 'Ensure all team members are available at the chosen time.', 'Prepare an agenda in advance.'], 'status': 'not started'}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"Julio\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd169364-f581-4e31-a802-bd311a8207c6",
   "metadata": {},
   "source": [
    "## Expliquemos en términos sencillos lo que acabamos de hacer\n",
    "\n",
    "Los dos bloques de código anteriores demuestran cómo el chatbot procesa la entrada (input) del usuario para agregar una nueva tarea a su **lista de tareas pendientes**, actualiza la memoria y recupera las tareas almacenadas para verificar la actualización. Aquí tienes una explicación sencilla:\n",
    "\n",
    "#### ¿Qué hace el código?\n",
    "\n",
    "1. **Entrada (input) del usuario para una tarea**:\n",
    "   - El usuario proporciona un mensaje con una tarea:  \n",
    "     ```\n",
    "     \"Programar la reunión mensual con el equipo de ventas de EE.UU.\"\n",
    "     ```\n",
    "   - Esta entrada indica una nueva tarea que el chatbot debe agregar a la **lista de tareas pendientes** del usuario.\n",
    "\n",
    "2. **Ejecutar el graph**:\n",
    "   - La función `graph.stream` procesa el mensaje utilizando el flujo de trabajo del chatbot.\n",
    "   - El flujo de trabajo determina que esta entrada está relacionada con una **tarea pendiente** y activa el nodo correspondiente (por ejemplo, `update_todos`).\n",
    "   - El sistema agrega la tarea a la memoria de la **lista de tareas pendientes** del usuario (`Julio`).\n",
    "   - La respuesta del chatbot (como una confirmación o retroalimentación) se transmite y se imprime usando `pretty_print()`.\n",
    "\n",
    "3. **Espacio de nombres para la memoria**:\n",
    "   - La variable `user_id` se establece en `\"Julio\"`, apuntando a la memoria específica del usuario.\n",
    "\n",
    "4. **Recuperar la lista de tareas pendientes**:\n",
    "   - La función `across_thread_memory.search((\"todo\", user_id))` busca todas las tareas almacenadas en la memoria bajo el espacio de nombres **\"todo\"** para Julio.\n",
    "   - Para cada tarea encontrada, se imprimen los detalles de la tarea (`memory.value`).\n",
    "\n",
    "\n",
    "#### ¿Cómo funciona?\n",
    "\n",
    "1. **Analizar la entrada (input)**:\n",
    "   - El chatbot identifica el mensaje como una tarea y decide agregarlo a la lista de tareas pendientes.\n",
    "\n",
    "2. **Almacenar la tarea**:\n",
    "   - La tarea se añade a la **memoria de la lista de tareas pendientes** de Julio en el almacenamiento a largo plazo (`across_thread_memory`).\n",
    "\n",
    "3. **Verificar la actualización**:\n",
    "   - La función de búsqueda recupera todas las tareas almacenadas en la lista de tareas pendientes de Julio.\n",
    "   - Imprimir `memory.value` confirma que la tarea se guardó correctamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765320c2-d943-46b2-8448-e22c9b888926",
   "metadata": {},
   "source": [
    "## ¿Y si quieres actualizar una tarea pendiente? Mira cómo puedes hacerlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7fae0b3b-c783-4d2a-9dd0-d94869bfc12e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "For the task to schedule monthly meeting with the USA Sales Team, I need to get that done by end of month.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_KPTq6T7WoGJtzVzwT1yU96GH)\n",
      " Call ID: call_KPTq6T7WoGJtzVzwT1yU96GH\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "No updates for ToDo.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've noted that the task to schedule the monthly meeting with the USA Sales Team needs to be completed by the end of the month. If there's anything else you'd like to adjust or add, just let me know!\n"
     ]
    }
   ],
   "source": [
    "# User input to update an existing ToDo\n",
    "input_messages = [HumanMessage(content=\"For the task to schedule monthly meeting with the USA Sales Team, I need to get that done by end of month.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7c7ca3-9303-4a91-8d5a-81dda08ad814",
   "metadata": {},
   "source": [
    "## Eso ha funcionado. Expliquemos cómo lo hemos hecho.\n",
    "\n",
    "El código anterior demuestra cómo el chatbot procesa la entrada (input) del usuario para **actualizar una tarea existente** en su **lista de tareas pendientes**, asegurando que los detalles de la tarea se modifiquen y almacenen correctamente. Aquí tienes una explicación sencilla:\n",
    "\n",
    "#### ¿Qué hace el código?\n",
    "\n",
    "1. **Entrada (input) del usuario para actualizar una tarea**:\n",
    "   - El usuario proporciona una actualización para una tarea existente:  \n",
    "     ```\n",
    "     \"Para la tarea de programar la reunión mensual con el equipo de ventas de EE.UU., necesito que esté lista antes de fin de mes.\"\n",
    "     ```\n",
    "   - Esta entrada especifica información adicional sobre la tarea (un plazo: \"fin de mes\").\n",
    "\n",
    "2. **Ejecutar el graph**:\n",
    "   - La función `graph.stream` procesa la entrada (input) utilizando el flujo de trabajo del chatbot.\n",
    "   - El flujo de trabajo identifica que esta entrada está relacionada con la **actualización de una tarea pendiente existente**.\n",
    "   - El chatbot modifica la tarea correspondiente en la **memoria de la lista de tareas pendientes** del usuario para incluir el nuevo plazo.\n",
    "\n",
    "3. **Transmitir resultados**:\n",
    "   - La respuesta del chatbot, que confirma la actualización de la tarea o proporciona retroalimentación, se transmite paso a paso.\n",
    "   - El último mensaje procesado se muestra en un formato amigable utilizando `pretty_print()`.\n",
    "\n",
    "\n",
    "#### ¿Cómo funciona?\n",
    "\n",
    "1. **Identificación de la tarea**:\n",
    "   - El chatbot busca en la **memoria de la lista de tareas pendientes** del usuario la tarea existente (\"programar la reunión mensual con el equipo de ventas de EE.UU.\").\n",
    "   - Identifica la tarea que coincide con la descripción del usuario.\n",
    "\n",
    "2. **Actualización de la tarea**:\n",
    "   - El chatbot actualiza la tarea añadiendo el plazo especificado (\"fin de mes\") a sus detalles.\n",
    "   - Modifica la entrada correspondiente en el almacenamiento a largo plazo.\n",
    "\n",
    "3. **Retroalimentación al usuario**:\n",
    "   - El chatbot puede confirmar la actualización generando una respuesta como:  \n",
    "     ```\n",
    "     \"He actualizado la tarea 'Programar la reunión mensual con el equipo de ventas de EE.UU.' para incluir un plazo de 'fin de mes'.\"\n",
    "     ```\n",
    "\n",
    "\n",
    "#### ¿Por qué es importante?\n",
    "\n",
    "1. **Actualización de tareas**: Demuestra cómo el chatbot puede modificar tareas existentes según la entrada del usuario, manteniendo la lista de tareas siempre actualizada.  \n",
    "2. **Memoria dinámica**: Muestra que el sistema de memoria no es estático, sino que puede adaptarse y evolucionar según las necesidades del usuario.  \n",
    "3. **Compromiso del usuario**: El chatbot proporciona una retroalimentación clara, asegurando que el usuario sepa que sus actualizaciones se aplicaron correctamente.  \n",
    "\n",
    "\n",
    "#### Ejemplo de salida (output)\n",
    "\n",
    "**Respuesta del chatbot**:  \n",
    "Mientras ejecuta el gráfico, el chatbot podría responder:  \n",
    "```\n",
    "\"He actualizado la tarea 'Programar la reunión mensual con el equipo de ventas de EE.UU.' para incluir un plazo de 'fin de mes'.\"\n",
    "```\n",
    "\n",
    "**Memoria actualizada**:  \n",
    "La tarea actualizada en memoria podría verse así:  \n",
    "```json\n",
    "{\n",
    "  \"task\": \"Programar la reunión mensual con el equipo de ventas de EE.UU.\",\n",
    "  \"status\": \"no iniciada\",\n",
    "  \"deadline\": \"fin de mes\"\n",
    "}\n",
    "```\n",
    "\n",
    "Esto confirma que el chatbot actualizó correctamente la tarea con la nueva información."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be8064a-6fa4-419b-9a72-6243fde05605",
   "metadata": {},
   "source": [
    "## Excelente. Finalmente, ingresemos una tercera tarea pendiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fd103d90-beb1-4114-8abb-f5078624ed43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Prepare the content for the meetings with Gen AI Teams of USA, Europe, and India.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_sDuVimTbek29UJyzczWuO34A)\n",
      " Call ID: call_sDuVimTbek29UJyzczWuO34A\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Updated ToDo: {'task': 'Prepare the content for the meetings with Gen AI Teams of USA, Europe, and India.', 'time_to_complete': 180, 'solutions': ['Research recent developments in AI relevant to each region.', 'Draft an agenda tailored to the interests and needs of each team.', 'Include discussion points on collaboration opportunities across regions.'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added \"Prepare the content for the meetings with Gen AI Teams of USA, Europe, and India\" to your ToDo list. If there's anything else you need, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# User input for a ToDo\n",
    "input_messages = [HumanMessage(content=\"Prepare the content for the meetings with Gen AI Teams of USA, Europe, and India.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fccc1f-64c6-47c9-8abe-3a9b7f0dc0ce",
   "metadata": {},
   "source": [
    "## Y, para finalizar este ejercicio, revisemos la lista actual de tareas pendientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a6a4c86-b158-4109-a4bf-ac310804f85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'Schedule interviews with candidates for California Sales Manager.', 'time_to_complete': 120, 'deadline': None, 'solutions': ['Use scheduling software like Calendly or Doodle to coordinate times.', 'Contact candidates via email or phone to confirm availability.', 'Coordinate with the hiring team to ensure their availability.'], 'status': 'not started'}\n",
      "{'task': 'Schedule monthly meeting with the USA Sales Team.', 'time_to_complete': 60, 'deadline': '2025-01-31T23:59:59', 'solutions': ['Use a recurring calendar event to schedule the meeting.', 'Ensure all team members are available at the chosen time.', 'Prepare an agenda in advance.'], 'status': 'not started'}\n",
      "{'task': 'Prepare the content for the meetings with Gen AI Teams of USA, Europe, and India.', 'time_to_complete': 180, 'deadline': None, 'solutions': ['Research recent developments in AI relevant to each region.', 'Draft an agenda tailored to the interests and needs of each team.', 'Include discussion points on collaboration opportunities across regions.'], 'status': 'not started'}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"Julio\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8719db1c-0d3f-4824-b610-66ef006e9213",
   "metadata": {},
   "source": [
    "## Una cosa más: veamos qué sucede cuando completamos una tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "501e7187-759f-4526-a503-ea617a56058d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I have completed the task Schedule interviews with candidates for California Sales Manager..\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_jkwZal7smCG2KYh3kpHt6rIO)\n",
      " Call ID: call_jkwZal7smCG2KYh3kpHt6rIO\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "No updates for ToDo.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Great job on completing the task to schedule interviews with candidates for the California Sales Manager position! If there's anything else you need help with, just let me know.\n"
     ]
    }
   ],
   "source": [
    "# User input to update an existing ToDo\n",
    "input_messages = [HumanMessage(content=\"I have completed the task Schedule interviews with candidates for California Sales Manager..\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e46868-81af-4f07-95f2-acd01c4ace2c",
   "metadata": {},
   "source": [
    "## ¿Ha cambiado el status de la tarea completada? Veamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3096c5ca-1fed-441c-99e5-4f3dcf0df2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task': 'Schedule interviews with candidates for California Sales Manager.', 'time_to_complete': 120, 'deadline': None, 'solutions': ['Use scheduling software like Calendly or Doodle to coordinate times.', 'Contact candidates via email or phone to confirm availability.', 'Coordinate with the hiring team to ensure their availability.'], 'status': 'done'}\n",
      "{'task': 'Schedule monthly meeting with the USA Sales Team.', 'time_to_complete': 60, 'deadline': '2025-01-31T23:59:59', 'solutions': ['Use a recurring calendar event to schedule the meeting.', 'Ensure all team members are available at the chosen time.', 'Prepare an agenda in advance.'], 'status': 'not started'}\n",
      "{'task': 'Prepare the content for the meetings with Gen AI Teams of USA, Europe, and India.', 'time_to_complete': 180, 'deadline': None, 'solutions': ['Research recent developments in AI relevant to each region.', 'Draft an agenda tailored to the interests and needs of each team.', 'Include discussion points on collaboration opportunities across regions.'], 'status': 'not started'}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"Julio\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"todo\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fcd995-b175-401f-b431-6301178b1471",
   "metadata": {},
   "source": [
    "* Como puedes ver, ahora **el status de la primera tarea aparece como \"completada\"**. A partir de este punto, podríamos seguir mejorando nuestro Agente en las direcciones que queramos explorar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c757839-7192-4f9b-9cd1-befff2398884",
   "metadata": {},
   "source": [
    "## Cómo ejecutar el código desde Visual Studio Code  \n",
    "* En Visual Studio Code, busca el archivo `028-agent-with-LT-memory.py`.  \n",
    "* En la terminal, asegúrate de estar en el directorio donde se encuentra el archivo y ejecuta:  \n",
    "    * `python 028-agent-with-LT-memory.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14adfb36-e0fd-4410-8134-9631ba1930cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
