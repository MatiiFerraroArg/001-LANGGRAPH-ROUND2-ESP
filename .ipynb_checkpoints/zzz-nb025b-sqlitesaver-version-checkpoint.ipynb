{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a7ac5fa-9b7e-492c-aa79-4c585cc65b03",
   "metadata": {},
   "source": [
    "# Re-writing the previous project with SQLiteSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be46161e-45e9-46d7-8214-bcbea10aff2e",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e0018-cba4-4959-881a-0a65093d202d",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4065e336-d054-412c-8a3f-1fbec63e1bcd",
   "metadata": {},
   "source": [
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dda8d4-80cf-4b8f-9981-94edda5e9911",
   "metadata": {},
   "source": [
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 002-setup.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af743328-1bc8-4b01-85fb-fcb21c6499c2",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863dd299-0780-49ad-a1b7-b76e249350da",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **001-langgraph**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e766aa-f3e2-491f-be99-d0c6b700d47a",
   "metadata": {},
   "source": [
    "## Track operations\n",
    "From now on, we can track the operations **and the cost** of this project from LangSmith:\n",
    "* [smith.langchain.com](https://smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f99504a-1b8f-4360-b342-0b81ffa06aff",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e5789-5bde-42e1-88dd-92dc8e363c24",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5514113-ddca-4ae9-9de6-0b9225b18f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fecd39d0-e72e-4bc2-8a68-2fa4008ea365",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f4a923-b19e-498e-9be5-e47ec4a77d80",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fef1e5c-b7e2-4a04-96c5-8f64377b8eba",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1cf94ae-6c39-4475-9c5b-4b74d8d78753",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189e9e17-dfb0-4fd3-85b9-1fba83771941",
   "metadata": {},
   "source": [
    "## Connect with an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21d23f4-61f5-4227-8a75-7eefde6680ee",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "148df8e0-361d-4ddd-8709-af48fa1648d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df978ec5-bfd2-4167-bd33-86bc2687d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chatModel35 = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chatModel4o = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5961f12a-3d59-44b9-b9de-85d75d8eab76",
   "metadata": {},
   "source": [
    "## Using SQLiteSaver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9374dc0-6c4f-4d67-b846-ecaa8cc9f0ff",
   "metadata": {},
   "source": [
    "## Step 1: Create this two empty databases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24383212-aced-48e6-ba01-113ee430f22c",
   "metadata": {},
   "source": [
    "To create the SQLite databases (`memory_store.db` and `checkpoint_store.db`) using the terminal, follow these simple steps:\n",
    "\n",
    "#### 1. Open Terminal\n",
    "- Press `Command + Space`, type **Terminal**, and hit `Enter`.\n",
    "\n",
    "#### 2. Navigate to Your Project Folder\n",
    "If your project is inside a folder like `~/my_project`, navigate to it:\n",
    "\n",
    "```sh\n",
    "cd ~/my_project\n",
    "```\n",
    "\n",
    "If you're unsure of your project location, use `ls` to list files and `cd folder_name` to enter a folder.\n",
    "\n",
    "#### 3. Create the SQLite Databases\n",
    "Run these commands to create empty SQLite databases:\n",
    "\n",
    "```sh\n",
    "sqlite3 memory_store.db \".databases\"\n",
    "sqlite3 checkpoint_store.db \".databases\"\n",
    "```\n",
    "\n",
    "This initializes the databases. You should see output confirming they exist.\n",
    "\n",
    "#### 4. Verify That the Databases Exist\n",
    "Run:\n",
    "\n",
    "```sh\n",
    "ls *.db\n",
    "```\n",
    "\n",
    "This should list:\n",
    "\n",
    "```\n",
    "memory_store.db  checkpoint_store.db\n",
    "```\n",
    "\n",
    "#### 5. (Optional) Check Database Content\n",
    "To check inside a database, open it with:\n",
    "\n",
    "```sh\n",
    "sqlite3 memory_store.db\n",
    "```\n",
    "\n",
    "Then list tables with:\n",
    "\n",
    "```sql\n",
    ".tables\n",
    "```\n",
    "\n",
    "To exit SQLite, type:\n",
    "\n",
    "```sh\n",
    ".exit\n",
    "```\n",
    "\n",
    "#### Done!\n",
    "Now your code should be able to use these databases without issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3cc7b9f-5cb7-4376-b014-f4aaa8693361",
   "metadata": {},
   "source": [
    "## Step 2: Run this code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd281ea-b2c2-4d5f-99cb-f7f456d25265",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "from langgraph.store.sqlite import SqliteStore\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "# Initialize SQLite storage\n",
    "sqlite_store = SqliteStore(db_path=\"memory_store.db\")\n",
    "sqlite_saver = SqliteSaver(db_path=\"checkpoint_store.db\")\n",
    "\n",
    "# Chat model \n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the LLM\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0) \n",
    "\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, MessagesState, START, END\n",
    "from langgraph.store.base import BaseStore\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful assistant with memory that provides information about the user. \n",
    "If you have memory for this user, use it to personalize your responses.\n",
    "Here is the memory (it may be empty): {memory}\"\"\"\n",
    "\n",
    "# Create new memory from the chat history and any existing memory\n",
    "CREATE_MEMORY_INSTRUCTION = \"\"\"You are collecting information about the user to personalize your responses.\n",
    "\n",
    "CURRENT USER INFORMATION:\n",
    "{memory}\n",
    "\n",
    "INSTRUCTIONS:\n",
    "1. Review the chat history below carefully\n",
    "2. Identify new information about the user, such as:\n",
    "   - Personal details (name, location)\n",
    "   - Preferences (likes, dislikes)\n",
    "   - Interests and hobbies\n",
    "   - Past experiences\n",
    "   - Goals or future plans\n",
    "3. Merge any new information with existing memory\n",
    "4. Format the memory as a clear, bulleted list\n",
    "5. If new information conflicts with existing memory, keep the most recent version\n",
    "\n",
    "Remember: Only include factual information directly stated by the user. Do not make assumptions or inferences.\n",
    "\n",
    "Based on the chat history below, please update the user information:\"\"\"\n",
    "\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Load memory from the store and use it to personalize the chatbot's response.\"\"\"\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"memory\", user_id)\n",
    "    key = \"user_memory\"\n",
    "    existing_memory = store.get(namespace, key)\n",
    "    existing_memory_content = existing_memory.value.get('memory') if existing_memory else \"No existing memory found.\"\n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(memory=existing_memory_content)\n",
    "    response = model.invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "def write_memory(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "    \"\"\"Reflect on the chat history and save a memory to the store.\"\"\"\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "    namespace = (\"memory\", user_id)\n",
    "    existing_memory = store.get(namespace, \"user_memory\")\n",
    "    existing_memory_content = existing_memory.value.get('memory') if existing_memory else \"No existing memory found.\"\n",
    "    system_msg = CREATE_MEMORY_INSTRUCTION.format(memory=existing_memory_content)\n",
    "    new_memory = model.invoke([SystemMessage(content=system_msg)]+state['messages'])\n",
    "    store.put(namespace, \"user_memory\", {\"memory\": new_memory.content})\n",
    "\n",
    "# Define the graph\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(\"call_model\", call_model)\n",
    "builder.add_node(\"write_memory\", write_memory)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"call_model\", \"write_memory\")\n",
    "builder.add_edge(\"write_memory\", END)\n",
    "\n",
    "# Compile the graph with the SQLite checkpointer and store\n",
    "graph = builder.compile(checkpointer=sqlite_saver, store=sqlite_store)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc24f4f-d23c-4202-992d-91b0623136ae",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 002-setup.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 002-setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1af248e-6069-44b3-a2cd-a20aa3259874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
